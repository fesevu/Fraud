{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ab3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.3.0\n",
      "Uninstalling torch-2.3.0:\n",
      "  Successfully uninstalled torch-2.3.0\n",
      "Found existing installation: torch-geometric 2.6.1\n",
      "Uninstalling torch-geometric-2.6.1:\n",
      "  Successfully uninstalled torch-geometric-2.6.1\n",
      "\u001b[33mWARNING: Skipping torch_scatter as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_sparse as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pyg_lib as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_cluster as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_spline_conv as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch==2.3.0\n",
      "  Using cached torch-2.3.0-cp39-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (4.13.2)\n",
      "Requirement already satisfied: sympy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from sympy->torch==2.3.0) (1.3.0)\n",
      "Using cached torch-2.3.0-cp39-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (3.11.18)\n",
      "Requirement already satisfied: fsspec in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from requests->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from requests->torch_geometric) (2025.4.26)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
      "Collecting torch_scatter\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_scatter-2.1.2-cp39-cp39-macosx_10_9_universal2.whl (555 kB)\n",
      "Collecting torch_sparse\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_sparse-0.6.18-cp39-cp39-macosx_11_0_universal2.whl (556 kB)\n",
      "Collecting torch_cluster\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_cluster-1.6.3-cp39-cp39-macosx_10_9_universal2.whl (600 kB)\n",
      "Collecting torch_spline_conv\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_spline_conv-1.2.2-cp39-cp39-macosx_10_9_universal2.whl (206 kB)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_sparse) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from scipy->torch_sparse) (2.0.2)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, torch_sparse, torch_cluster\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torch_cluster]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch_cluster-1.6.3 torch_scatter-2.1.2 torch_sparse-0.6.18 torch_spline_conv-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: pandas in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: graphviz in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (0.20.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (3.2.1)\n",
      "Requirement already satisfied: seaborn in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall torch torch_geometric torch_scatter torch_sparse pyg_lib torch_cluster torch_spline_conv -y\n",
    "# 2.1 PyTorch (CPU) – подмените индекс, если нужна CUDA\n",
    "%pip install torch==2.3.0\n",
    "\n",
    "# 2.2 PyG: с 2.3+ внешних библиотек почти нет, ставим одной строкой\n",
    "%pip install torch_geometric\n",
    "%pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
    "\n",
    "\n",
    "# 2.4 остальное\n",
    "%pip install xgboost pandas matplotlib graphviz scikit-learn tqdm numpy networkx seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f797bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.utils import to_undirected\n",
    "import math\n",
    "import torch_cluster\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb6648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36105035",
   "metadata": {},
   "source": [
    "# Чтение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7636f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ACCOUNTS_CSV = Path('./tmp/Ethereum/account.csv')      # обновите при необходимости\n",
    "TXS_CSV      = Path('./tmp/Ethereum/transaction.csv')   # обновите при необходимости\n",
    "\n",
    "assert ACCOUNTS_CSV.exists(), f'{ACCOUNTS_CSV} not found'\n",
    "assert TXS_CSV.exists(), f'{TXS_CSV} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f88c6572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x8335392fe1b236296c5d5f653264396de165e46c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x9d4b62503b4b7993182323effe6245f6d77e4413</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc91293245b669da19a96cd85d40bb9c203359657</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1056d8d9ebb0e0d8710a0e2a1852d4a09d56464a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x4f1872383be22878af5d4795b69be61b35ec5d10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  label\n",
       "0  0x8335392fe1b236296c5d5f653264396de165e46c   True\n",
       "1  0x9d4b62503b4b7993182323effe6245f6d77e4413   True\n",
       "2  0xc91293245b669da19a96cd85d40bb9c203359657   True\n",
       "3  0x1056d8d9ebb0e0d8710a0e2a1852d4a09d56464a   True\n",
       "4  0x4f1872383be22878af5d4795b69be61b35ec5d10   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x21f74c6bbc1e3ab9f0205e12de3a9daa14351aed</td>\n",
       "      <td>0x46f1c0481803cb34a7860d614b5430c5db51bfb7</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.502740e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x54008c2684d96c44a094dc127842ec144b157e96</td>\n",
       "      <td>0x1acee83486b6671b005eed45c9fb9277e7eeb63d</td>\n",
       "      <td>2.34758</td>\n",
       "      <td>1.518731e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x97aeb9b292c00405e145d9c7a8429bc970fa0e65</td>\n",
       "      <td>0x4f00b95c625c6d6ef72748d78c750fd6c84a8b85</td>\n",
       "      <td>0.01003</td>\n",
       "      <td>1.516224e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2dfdf31bbc29468d487591f292872a14c1f8d1f0</td>\n",
       "      <td>0x474057adf42f9f955e86aa1142740f9d7763e41e</td>\n",
       "      <td>0.51587</td>\n",
       "      <td>1.522422e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x5b39067ee0309856edd13f23c9c1793f9fda1b4f</td>\n",
       "      <td>0x6376baf58c4c5d70ba8fca9565b6955f07c584a9</td>\n",
       "      <td>6.67000</td>\n",
       "      <td>1.514817e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          src  \\\n",
       "0  0x21f74c6bbc1e3ab9f0205e12de3a9daa14351aed   \n",
       "1  0x54008c2684d96c44a094dc127842ec144b157e96   \n",
       "2  0x97aeb9b292c00405e145d9c7a8429bc970fa0e65   \n",
       "3  0x2dfdf31bbc29468d487591f292872a14c1f8d1f0   \n",
       "4  0x5b39067ee0309856edd13f23c9c1793f9fda1b4f   \n",
       "\n",
       "                                          dst   amount     timestamp  \n",
       "0  0x46f1c0481803cb34a7860d614b5430c5db51bfb7  5.00000  1.502740e+09  \n",
       "1  0x1acee83486b6671b005eed45c9fb9277e7eeb63d  2.34758  1.518731e+09  \n",
       "2  0x4f00b95c625c6d6ef72748d78c750fd6c84a8b85  0.01003  1.516224e+09  \n",
       "3  0x474057adf42f9f955e86aa1142740f9d7763e41e  0.51587  1.522422e+09  \n",
       "4  0x6376baf58c4c5d70ba8fca9565b6955f07c584a9  6.67000  1.514817e+09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_df = pd.read_csv(ACCOUNTS_CSV, header=None, names=['id', 'label'])\n",
    "tx_df  = pd.read_csv(TXS_CSV, header=None, names=['src', 'dst', 'amount', 'timestamp'])\n",
    "\n",
    "display(acc_df.head())\n",
    "display(tx_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66514556",
   "metadata": {},
   "source": [
    "## 🏗️ Сборка графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48b4cfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Граф содержит 32,168 узлов и 42,044 рёбер\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "for _, row in acc_df.iterrows():\n",
    "    G.add_node(row.id, label=int(bool(row.label)))\n",
    "\n",
    "# add edges\n",
    "for _, row in tx_df.iterrows():\n",
    "    G.add_edge(row.src, row.dst, amount=float(row.amount), ts=float(row.timestamp))\n",
    "\n",
    "print(f'Граф содержит {G.number_of_nodes():,} узлов и {G.number_of_edges():,} рёбер')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2df1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Calculating extra graph features…\n"
     ]
    }
   ],
   "source": [
    "# Структурные признаки\n",
    "in_deg  = dict(G.in_degree())\n",
    "out_deg = dict(G.out_degree())\n",
    "\n",
    "# Финансовые суммы\n",
    "sent_sum = {n: 0.0 for n in G.nodes()}\n",
    "recv_sum = {n: 0.0 for n in G.nodes()}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    amt = d['amount']\n",
    "    sent_sum[u] += amt\n",
    "    recv_sum[v] += amt\n",
    "\n",
    "# PageRank и кластерный коэффициент\n",
    "pr = nx.pagerank(G, alpha=0.85)\n",
    "clust = nx.clustering(G.to_undirected())\n",
    "\n",
    "# Записываем фичи в граф\n",
    "for n in G.nodes():\n",
    "    G.nodes[n].update({\n",
    "        'in_deg':      in_deg.get(n, 0),\n",
    "        'out_deg':     out_deg.get(n, 0),\n",
    "        'sent_sum':    sent_sum[n],\n",
    "        'recv_sum':    recv_sum[n],\n",
    "        'net_sum':     sent_sum[n] - recv_sum[n],\n",
    "        'pagerank':    pr[n],\n",
    "        'clustering':  clust[n],\n",
    "    })\n",
    "\n",
    "# --- после расчёта pr и clust --------------------------------------------\n",
    "print('⏳ Calculating extra graph features…')\n",
    "\n",
    "# 1) Betweenness (approx)\n",
    "btw = nx.betweenness_centrality(G, k=10_000, seed=42, normalized=True)\n",
    "\n",
    "# 2) Weakly-connected component size\n",
    "G_u = G.to_undirected()\n",
    "wcc = {n: 0 for n in G}\n",
    "for comp in nx.connected_components(G_u):\n",
    "    size = len(comp)\n",
    "    for n in comp:\n",
    "        wcc[n] = size\n",
    "\n",
    "# 3) Min amounts\n",
    "send_min = {n: math.inf for n in G}\n",
    "recv_min = {n: math.inf for n in G}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    amt = d['amount']\n",
    "    send_min[u] = min(send_min[u], amt)\n",
    "    recv_min[v] = min(recv_min[v], amt)\n",
    "# заменяем inf → 0.0 (узлы без операций)\n",
    "send_min = {n: 0.0 if math.isinf(v) else v for n, v in send_min.items()}\n",
    "recv_min = {n: 0.0 if math.isinf(v) else v for n, v in recv_min.items()}\n",
    "\n",
    "# --- записываем все новые фичи в вершины ----------------------------------\n",
    "for n in G.nodes():\n",
    "    G.nodes[n].update({\n",
    "        'btw_centr':   btw[n],\n",
    "        'wcc_size':    wcc[n],\n",
    "        'send_min':    send_min[n],\n",
    "        'recv_min':    recv_min[n],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebfeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Training Node2Vec…\n",
      "Epoch 1, Loss 246.0344\n",
      "Epoch 2, Loss 185.5990\n",
      "Epoch 3, Loss 150.2787\n",
      "Epoch 4, Loss 122.1331\n",
      "Epoch 5, Loss 99.6138\n"
     ]
    }
   ],
   "source": [
    " # --- перед обучением Node2Vec: создаём маппинг id → idx -------------------\n",
    "id2idx = {n: i for i, n in enumerate(G.nodes())}\n",
    "\n",
    "# --- строим edge_index по числовым индексам ------------------------------\n",
    "edges = list(G.edges())\n",
    "row = [id2idx[u] for u, v in edges]\n",
    "col = [id2idx[v] for u, v in edges]\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index).contiguous()\n",
    "\n",
    "# --- теперь обучаем Node2Vec на неориентированном графе --------------------\n",
    "print('⏳ Training Node2Vec…')\n",
    "n2v = Node2Vec(\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=G.number_of_nodes(),\n",
    "    embedding_dim=128,\n",
    "    walk_length=20,\n",
    "    context_size=10,\n",
    "    walks_per_node=5,\n",
    "    num_negative_samples=1,\n",
    "    sparse=True,\n",
    "    p=1, q=1\n",
    ").to(device)\n",
    "\n",
    "loader = n2v.loader(batch_size=1024, shuffle=True)\n",
    "opt = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "n2v.train()\n",
    "for epoch in range(40):  # можете увеличить число эпох\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        opt.zero_grad()\n",
    "        loss = n2v.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss {total_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c44daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример фич узла: ('0x8335392fe1b236296c5d5f653264396de165e46c', {'label': 1, 'in_deg': 4, 'out_deg': 1, 'sent_sum': 3.49954, 'recv_sum': 3.4999599999999997, 'net_sum': -0.0004199999999996429, 'pagerank': 4.475874254314406e-05, 'clustering': 0, 'btw_centr': 0.0, 'wcc_size': 30701, 'send_min': 3.49954, 'recv_min': 0.5, 'n2v': tensor([-0.3263, -0.9942, -0.4803,  0.5377, -0.5554, -0.6436,  0.5854, -0.8306,\n",
      "         0.4574,  0.8498,  1.2007, -1.0742, -0.5128, -0.3223, -0.0596, -0.1528,\n",
      "         0.9123,  0.5771,  0.8630,  1.2475, -0.4094, -0.5058, -0.5839, -1.5232,\n",
      "        -0.4698, -0.3420,  0.9764,  0.1384, -0.5216, -0.3267,  0.4469, -0.4312,\n",
      "         0.1008, -1.3053,  0.7192, -1.2030,  0.0521, -0.1258,  0.6617,  0.0397,\n",
      "        -0.6533, -0.6969, -0.6242, -0.0925,  0.2065,  0.6458,  0.6187,  0.5766,\n",
      "         1.0146,  0.9408,  0.5583,  0.5236, -0.3055,  0.9530, -0.2336, -0.7888,\n",
      "        -1.3516,  0.7423,  0.7200,  0.6539,  0.5183,  0.2476,  0.2971, -0.5402,\n",
      "        -0.7539,  0.5327,  0.2945,  0.2118, -0.4394,  0.7294,  0.0765, -0.6604,\n",
      "        -0.4716,  0.9292, -1.7458, -0.2163, -1.5390,  0.4313, -0.3803, -0.6656,\n",
      "         0.6118, -0.6845, -0.0481,  0.0955, -1.3548,  0.3945, -1.1022, -0.7895,\n",
      "         1.0226, -0.7264,  0.1274,  1.5636, -0.1402, -0.0279,  0.6717,  0.0756,\n",
      "        -1.6913,  1.1608, -2.1397,  0.8735, -0.1010,  0.4316,  0.6063, -1.4522,\n",
      "         0.7987, -1.2305,  0.4260,  0.1482,  0.1372, -0.5678,  1.6804,  0.2843,\n",
      "         0.0851, -1.1955, -1.7678,  0.6235,  0.3008, -1.1160,  0.7538,  0.4405,\n",
      "        -1.2386, -0.7804, -1.0747, -0.7735,  0.4157, -1.3152,  0.4489, -1.3814]), 'x': tensor([ 4.0000e+00,  1.0000e+00,  3.4995e+00,  3.5000e+00, -4.2000e-04,\n",
      "         4.4759e-05,  0.0000e+00,  0.0000e+00,  3.0701e+04,  3.4995e+00,\n",
      "         5.0000e-01, -3.2634e-01, -9.9416e-01, -4.8025e-01,  5.3774e-01,\n",
      "        -5.5543e-01, -6.4363e-01,  5.8538e-01, -8.3065e-01,  4.5737e-01,\n",
      "         8.4977e-01,  1.2007e+00, -1.0742e+00, -5.1282e-01, -3.2226e-01,\n",
      "        -5.9591e-02, -1.5277e-01,  9.1232e-01,  5.7713e-01,  8.6297e-01,\n",
      "         1.2475e+00, -4.0944e-01, -5.0577e-01, -5.8387e-01, -1.5232e+00,\n",
      "        -4.6978e-01, -3.4200e-01,  9.7636e-01,  1.3835e-01, -5.2155e-01,\n",
      "        -3.2671e-01,  4.4686e-01, -4.3124e-01,  1.0085e-01, -1.3053e+00,\n",
      "         7.1919e-01, -1.2030e+00,  5.2142e-02, -1.2579e-01,  6.6175e-01,\n",
      "         3.9725e-02, -6.5328e-01, -6.9692e-01, -6.2423e-01, -9.2545e-02,\n",
      "         2.0654e-01,  6.4582e-01,  6.1867e-01,  5.7658e-01,  1.0146e+00,\n",
      "         9.4077e-01,  5.5833e-01,  5.2360e-01, -3.0549e-01,  9.5300e-01,\n",
      "        -2.3358e-01, -7.8878e-01, -1.3516e+00,  7.4235e-01,  7.2003e-01,\n",
      "         6.5390e-01,  5.1832e-01,  2.4759e-01,  2.9709e-01, -5.4023e-01,\n",
      "        -7.5392e-01,  5.3274e-01,  2.9453e-01,  2.1183e-01, -4.3939e-01,\n",
      "         7.2941e-01,  7.6488e-02, -6.6044e-01, -4.7161e-01,  9.2924e-01,\n",
      "        -1.7458e+00, -2.1633e-01, -1.5390e+00,  4.3133e-01, -3.8035e-01,\n",
      "        -6.6558e-01,  6.1180e-01, -6.8449e-01, -4.8065e-02,  9.5483e-02,\n",
      "        -1.3548e+00,  3.9452e-01, -1.1022e+00, -7.8952e-01,  1.0226e+00,\n",
      "        -7.2641e-01,  1.2745e-01,  1.5636e+00, -1.4022e-01, -2.7914e-02,\n",
      "         6.7166e-01,  7.5606e-02, -1.6913e+00,  1.1608e+00, -2.1397e+00,\n",
      "         8.7351e-01, -1.0098e-01,  4.3158e-01,  6.0630e-01, -1.4522e+00,\n",
      "         7.9868e-01, -1.2305e+00,  4.2598e-01,  1.4818e-01,  1.3715e-01,\n",
      "        -5.6785e-01,  1.6804e+00,  2.8426e-01,  8.5132e-02, -1.1955e+00,\n",
      "        -1.7678e+00,  6.2352e-01,  3.0078e-01, -1.1160e+00,  7.5381e-01,\n",
      "         4.4053e-01, -1.2386e+00, -7.8036e-01, -1.0747e+00, -7.7349e-01,\n",
      "         4.1574e-01, -1.3152e+00,  4.4885e-01, -1.3814e+00])})\n"
     ]
    }
   ],
   "source": [
    "# --- извлекаем эмбеддинги и записываем обратно в G ------------------------\n",
    "z = n2v.embedding.weight.detach().cpu()\n",
    "for n, idx in id2idx.items():\n",
    "    G.nodes[n]['n2v'] = z[idx]\n",
    "\n",
    "# --- при формировании data.x ---------------------------------------------\n",
    "# Наконец, собираем x\n",
    "num_attr_keys = [\n",
    "    'in_deg','out_deg','sent_sum','recv_sum','net_sum',\n",
    "    'pagerank','clustering',\n",
    "    'btw_centr','wcc_size','send_min','recv_min'\n",
    "]\n",
    "\n",
    "for n in G.nodes():\n",
    "    # проверяем, что всё есть\n",
    "    missing = [k for k in num_attr_keys if k not in G.nodes[n]]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"У узла {n} нет фичей {missing}\")\n",
    "    base = [float(G.nodes[n][k]) for k in num_attr_keys]\n",
    "    emb  = G.nodes[n]['n2v'].tolist()           # 128-мерный эмбеддинг\n",
    "    G.nodes[n]['x'] = torch.tensor(base + emb, dtype=torch.float)\n",
    "\n",
    "print('Пример фич узла:', list(G.nodes(data=True))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e646328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Делаем так, чтобы у всех узлов была метка\n",
    "nx.set_node_attributes(G, -1, \"label\")        # сначала всем ставим -1\n",
    "for _, row in acc_df.iterrows():              # затем переопределяем тем, что есть в accounts.csv\n",
    "    G.nodes[row.id][\"label\"] = int(bool(row.label))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9751011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# после формирования всех численных признаков, до отправки в PyG\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.stack([G.nodes[n]['x'].numpy() for n in G.nodes()])\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "for n, vec in zip(G.nodes(), X):\n",
    "    G.nodes[n]['x'] = torch.tensor(vec, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4c1f2",
   "metadata": {},
   "source": [
    "## 🔄 Конвертация в `torch_geometric.data.Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2a06745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 7\n",
      "Data(edge_index=[2, 42044], label=[32168], in_deg=[32168], out_deg=[32168], sent_sum=[32168], recv_sum=[32168], net_sum=[32168], pagerank=[32168], clustering=[32168], btw_centr=[32168], wcc_size=[32168], send_min=[32168], recv_min=[32168], n2v=[32168, 128], amount=[42044], ts=[42044], x=[32168, 7], y=[32168])\n"
     ]
    }
   ],
   "source": [
    "num_attr_keys = ['in_deg','out_deg','sent_sum','recv_sum','net_sum','pagerank','clustering']\n",
    "\n",
    "for n in G.nodes():\n",
    "    G.nodes[n]['x'] = torch.tensor([float(G.nodes[n][k]) for k in num_attr_keys], dtype=torch.float)\n",
    "\n",
    "data = from_networkx(G, group_node_attrs=['x'])\n",
    "data.y = torch.tensor([G.nodes[n].get('label', -1) for n in G.nodes()], dtype=torch.long)\n",
    "\n",
    "print(\"Num features:\", data.num_node_features)  \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9aa85510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now num features: 139\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1) Список «старых» фичей уже в data.x: shape [N,7]\n",
    "X_base = data.x                # float32, device может быть CPU или CUDA\n",
    "\n",
    "# 2) Достаём остальные скалярные фичи и приводим к форме [N,1]\n",
    "btw      = data.btw_centr.view(-1,1)   # [N] → [N,1]\n",
    "wcc      = data.wcc_size.view(-1,1)\n",
    "send_min = data.send_min.view(-1,1)\n",
    "recv_min = data.recv_min.view(-1,1)\n",
    "\n",
    "# 3) Node2Vec: shape [N,128]\n",
    "X_n2v    = data.n2v               # уже [N,128]\n",
    "\n",
    "# 4) Конкатенируем всё в один [N, 7+4+128 = 139]\n",
    "data.x = torch.cat([X_base, btw, wcc, send_min, recv_min, X_n2v], dim=1)\n",
    "\n",
    "print(\"Now num features:\", data.x.size(1))  # должно быть 139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc25dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) выгружаем data.x в NumPy\n",
    "X = data.x.cpu().numpy()   # shape [N,139]\n",
    "\n",
    "# 2) лог-трансформации неотрицательных признаков\n",
    "log_idxs = [0,1,2,3,7,8,9,10]\n",
    "X[:, log_idxs] = np.log1p(X[:, log_idxs])\n",
    "\n",
    "# 3) чистим NaN/Inf → конечные числа\n",
    "#    nan → 0.0, +inf → max_float32, -inf → min_float32\n",
    "X = np.nan_to_num(\n",
    "    X,\n",
    "    nan=0.0,\n",
    "    posinf=np.finfo(np.float32).max,\n",
    "    neginf=np.finfo(np.float32).min\n",
    ")\n",
    "\n",
    "# (можно проверить, что теперь все конечные)\n",
    "assert np.isfinite(X).all(), \"Есть ещё не-конечные элементы!\"\n",
    "\n",
    "# 4) стандартизация\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 5) обратно в TorchTensor\n",
    "import torch\n",
    "data.x = torch.tensor(X, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cd688",
   "metadata": {},
   "source": [
    "## ✂️ Train / Val / Test сплит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f9609b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 60.10%, Val: 20.03%, Test: 19.87%\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1) Собираем список узлов в порядке G.nodes()\n",
    "nodes = list(G.nodes())\n",
    "\n",
    "# 2) Хешируем каждый ID (md5 → целое), берём mod 100 → [0..99]\n",
    "hash_vals = np.array([\n",
    "    int(hashlib.md5(str(n).encode()).hexdigest(), 16) % 100\n",
    "    for n in nodes\n",
    "])\n",
    "\n",
    "# 3) Порог: [0,59] → train, [60,79] → val, [80,99] → test\n",
    "train_mask = torch.tensor(hash_vals < 60, dtype=torch.bool)\n",
    "val_mask   = torch.tensor((hash_vals >= 60) & (hash_vals < 80), dtype=torch.bool)\n",
    "test_mask  = torch.tensor(hash_vals >= 80, dtype=torch.bool)\n",
    "\n",
    "# 4) Привязываем к data\n",
    "data.train_mask = train_mask\n",
    "data.val_mask   = val_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "# Проверим доли\n",
    "print(f\"Train: {train_mask.sum().item()/len(nodes):.2%}, \"\n",
    "      f\"Val: {val_mask.sum().item()/len(nodes):.2%}, \"\n",
    "      f\"Test: {test_mask.sum().item()/len(nodes):.2%}\")\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.train_mask,        # корневые узлы для train\n",
    "    num_neighbors=[25, 15],             # сколько соседей на каждом слое\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.val_mask,\n",
    "    num_neighbors=[25, 15],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.test_mask,\n",
    "    num_neighbors=[25, 15],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1143320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сериализовано в /Users/a1234/Fraud/gnn/artifacts/eth_graph.pt\n"
     ]
    }
   ],
   "source": [
    "OUT_PATH = Path('./artifacts/eth_graph.pt')\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(data, OUT_PATH)\n",
    "print(f'Сериализовано в {OUT_PATH.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e9339",
   "metadata": {},
   "source": [
    "## 🧠 Определение GNN‑модели (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7823c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "# 1) Определяем GraphSAGE\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee4b5e",
   "metadata": {},
   "source": [
    "## 🏃‍♂️ Обучение и валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: normal=1.00, fraud=1.72\n",
      "Epoch 01 | Loss 0.3389 | Train Acc 0.095 | Val Acc 0.099\n",
      "Epoch 02 | Loss 0.1178 | Train Acc 0.095 | Val Acc 0.095\n",
      "Epoch 03 | Loss 0.0526 | Train Acc 0.097 | Val Acc 0.098\n",
      "Epoch 04 | Loss 0.0385 | Train Acc 0.097 | Val Acc 0.098\n",
      "Epoch 05 | Loss 0.0221 | Train Acc 0.097 | Val Acc 0.098\n",
      "Epoch 06 | Loss 0.0209 | Train Acc 0.098 | Val Acc 0.098\n",
      "Epoch 07 | Loss 0.0067 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 08 | Loss 0.0036 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 09 | Loss 0.0024 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 10 | Loss 0.0020 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 11 | Loss 0.0018 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 12 | Loss 0.0018 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 13 | Loss 0.0020 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 14 | Loss 0.0020 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 15 | Loss 0.0020 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 16 | Loss 0.0021 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 17 | Loss 0.0021 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 18 | Loss 0.0020 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 19 | Loss 0.0021 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 20 | Loss 0.0021 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 21 | Loss 0.0021 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 22 | Loss 0.0095 | Train Acc 0.097 | Val Acc 0.098\n",
      "Epoch 23 | Loss 0.1278 | Train Acc 0.090 | Val Acc 0.090\n",
      "Epoch 24 | Loss 0.2921 | Train Acc 0.095 | Val Acc 0.098\n",
      "Epoch 25 | Loss 0.0911 | Train Acc 0.097 | Val Acc 0.097\n",
      "Epoch 26 | Loss 0.0250 | Train Acc 0.097 | Val Acc 0.099\n",
      "Epoch 27 | Loss 0.0080 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 28 | Loss 0.0041 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 29 | Loss 0.0028 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 30 | Loss 0.0021 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 31 | Loss 0.0019 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 32 | Loss 0.0017 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 33 | Loss 0.0016 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 34 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 35 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 36 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 37 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 38 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 39 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 40 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 41 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 42 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 43 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 44 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 45 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 46 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 47 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 48 | Loss 0.0016 | Train Acc 0.098 | Val Acc 0.100\n",
      "Epoch 49 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.099\n",
      "Epoch 50 | Loss 0.0015 | Train Acc 0.098 | Val Acc 0.099\n",
      "✅ Test Accuracy: 0.083\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "labels = data.y[data.y != -1]\n",
    "counts = torch.bincount(labels)\n",
    "weight = torch.tensor([1.0, counts[0].float() / counts[1].float()], device=device)\n",
    "print(f\"Class weights: normal={weight[0]:.2f}, fraud={weight[1]:.2f}\")\n",
    "\n",
    "# 3) Инициализируем модель, optimizer, criterion (с весами из шага 2)\n",
    "model = GraphSAGE(data.num_node_features, 64, int(data.y.max().item())+1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weight, ignore_index=-1)\n",
    "\n",
    "# 4) Цикл обучения\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        # только первые batch.batch_size предсказаний — для корневых узлов\n",
    "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.batch_size\n",
    "    return total_loss / int(data.train_mask.sum())\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        logits = out[:batch.batch_size]\n",
    "        y = batch.y[:batch.batch_size]\n",
    "\n",
    "        # Только размеченные\n",
    "        mask = (y != -1)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += int((preds[mask] == y[mask]).sum())\n",
    "        total   += int(mask.sum())\n",
    "\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train_epoch()\n",
    "    train_acc = eval_loader(train_loader)\n",
    "    val_acc   = eval_loader(val_loader)\n",
    "    print(f'Epoch {epoch:02d} | Loss {loss:.4f} | Train Acc {train_acc:.3f} | Val Acc {val_acc:.3f}')\n",
    "\n",
    "test_acc = eval_loader(test_loader)\n",
    "print(f'✅ Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115f6d0",
   "metadata": {},
   "source": [
    "## 📊 Визуализация результатов\n",
    "Вычислим метрики на тестовой выборке и отобразим матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.944     0.905     0.924       369\n",
      "           1      0.850     0.908     0.878       218\n",
      "\n",
      "    accuracy                          0.906       587\n",
      "   macro avg      0.897     0.907     0.901       587\n",
      "weighted avg      0.909     0.906     0.907       587\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "for batch in test_loader:\n",
    "    batch = batch.to(device)\n",
    "    out = model(batch.x, batch.edge_index)\n",
    "    logits = out[:batch.batch_size]\n",
    "    y = batch.y[:batch.batch_size]\n",
    "    mask = (y != -1)\n",
    "\n",
    "    all_preds.append(logits.argmax(dim=1)[mask].cpu())\n",
    "    all_labels.append(y[mask].cpu())\n",
    "\n",
    "y_true = torch.cat(all_labels).numpy()\n",
    "y_pred = torch.cat(all_preds).numpy()\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix (Test)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f0a29",
   "metadata": {},
   "source": [
    "## 🕵️‍♂️ Интерпретация предсказаний с **GNNExplainer**\n",
    "Выберем произвольный корректно классифицированный узел из тестовой выборки и посмотрим, какие рёбра и признаки были наиболее важны для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e96cf",
   "metadata": {},
   "source": [
    "## 💾 Сохранение обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b195ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в /Users/a1234/Fraud/gnn/checkpoints/gcn_model.pt\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = Path('./checkpoints/gcn_model.pt')\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f'Модель сохранена в {MODEL_PATH.resolve()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
