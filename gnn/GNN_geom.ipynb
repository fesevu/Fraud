{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ab3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.4.0\n",
      "Uninstalling torch-2.4.0:\n",
      "  Successfully uninstalled torch-2.4.0\n",
      "Found existing installation: torch-geometric 2.6.1\n",
      "Uninstalling torch-geometric-2.6.1:\n",
      "  Successfully uninstalled torch-geometric-2.6.1\n",
      "Found existing installation: pyg-lib 0.4.0+pt24\n",
      "Uninstalling pyg-lib-0.4.0+pt24:\n",
      "  Successfully uninstalled pyg-lib-0.4.0+pt24\n",
      "Found existing installation: torch_sparse 0.6.18\n",
      "Uninstalling torch_sparse-0.6.18:\n",
      "  Successfully uninstalled torch_sparse-0.6.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch==2.4.0\n",
      "  Using cached torch-2.4.0-cp38-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: torchvision in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (0.19.0)\n",
      "Requirement already satisfied: torchaudio in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.0) (4.13.2)\n",
      "Requirement already satisfied: sympy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.0) (2025.3.0)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from jinja2->torch==2.4.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Using cached torch-2.4.0-cp38-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (3.10.11)\n",
      "Requirement already satisfied: fsspec in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: requests in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from aiohttp->torch_geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch_geometric) (2025.4.26)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.13.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
      "Collecting pyg_lib\n",
      "  Using cached https://data.pyg.org/whl/torch-2.4.0%2Bcpu/pyg_lib-0.4.0%2Bpt24-cp38-cp38-macosx_14_0_universal2.whl (1.5 MB)\n",
      "Requirement already satisfied: torch_scatter in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.1.2)\n",
      "Collecting torch_sparse\n",
      "  Using cached https://data.pyg.org/whl/torch-2.4.0%2Bcpu/torch_sparse-0.6.18-cp38-cp38-macosx_11_0_universal2.whl (586 kB)\n",
      "Requirement already satisfied: torch_cluster in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.6.3)\n",
      "Requirement already satisfied: torch_spline_conv in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch_sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scipy->torch_sparse) (1.24.4)\n",
      "Installing collected packages: pyg_lib, torch_sparse\n",
      "Successfully installed pyg_lib-0.4.0+pt24 torch_sparse-0.6.18\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.1.4)\n",
      "Requirement already satisfied: pandas in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: matplotlib in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: graphviz in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (0.20.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (3.1)\n",
      "Requirement already satisfied: seaborn in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (0.13.2)\n",
      "Collecting rdkit\n",
      "  Downloading rdkit-2024.3.5-cp38-cp38-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading rdkit-2024.3.5-cp38-cp38-macosx_11_0_arm64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rdkit\n",
      "Successfully installed rdkit-2024.3.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall torch torch_geometric pyg-lib torch-sparse -y\n",
    "# 2.1 PyTorch (CPU) – подмените индекс, если нужна CUDA\n",
    "%pip install torch==2.4.0 torchvision torchaudio\n",
    "\n",
    "# 2.2 PyG: с 2.3+ внешних библиотек почти нет, ставим одной строкой\n",
    "%pip install torch_geometric \n",
    "%pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
    "\n",
    "\n",
    "# 2.4 остальное\n",
    "%pip install xgboost pandas matplotlib graphviz scikit-learn tqdm numpy networkx seaborn rdkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f797bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1234/Fraud/.venv/lib/python3.8/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/a1234/Fraud/.venv/lib/python3.8/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.8/Python\n",
      "  Referenced from: <FC2050EE-717A-3D68-82A8-EA7E2DF7A741> /Users/a1234/Fraud/.venv/lib/python3.8/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.8/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.8/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.8/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/a1234/Fraud/.venv/lib/python3.8/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/a1234/Fraud/.venv/lib/python3.8/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.8/Python\n",
      "  Referenced from: <FC2050EE-717A-3D68-82A8-EA7E2DF7A741> /Users/a1234/Fraud/.venv/lib/python3.8/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.8/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.8/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.8/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.utils import to_undirected\n",
    "import math\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36105035",
   "metadata": {},
   "source": [
    "# Чтение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7636f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ACCOUNTS_CSV = Path('./tmp/Ethereum/account.csv')      # обновите при необходимости\n",
    "TXS_CSV      = Path('./tmp/Ethereum/transaction.csv')   # обновите при необходимости\n",
    "\n",
    "assert ACCOUNTS_CSV.exists(), f'{ACCOUNTS_CSV} not found'\n",
    "assert TXS_CSV.exists(), f'{TXS_CSV} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88c6572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x8335392fe1b236296c5d5f653264396de165e46c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x9d4b62503b4b7993182323effe6245f6d77e4413</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc91293245b669da19a96cd85d40bb9c203359657</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1056d8d9ebb0e0d8710a0e2a1852d4a09d56464a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x4f1872383be22878af5d4795b69be61b35ec5d10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  label\n",
       "0  0x8335392fe1b236296c5d5f653264396de165e46c   True\n",
       "1  0x9d4b62503b4b7993182323effe6245f6d77e4413   True\n",
       "2  0xc91293245b669da19a96cd85d40bb9c203359657   True\n",
       "3  0x1056d8d9ebb0e0d8710a0e2a1852d4a09d56464a   True\n",
       "4  0x4f1872383be22878af5d4795b69be61b35ec5d10   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x21f74c6bbc1e3ab9f0205e12de3a9daa14351aed</td>\n",
       "      <td>0x46f1c0481803cb34a7860d614b5430c5db51bfb7</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.502740e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x54008c2684d96c44a094dc127842ec144b157e96</td>\n",
       "      <td>0x1acee83486b6671b005eed45c9fb9277e7eeb63d</td>\n",
       "      <td>2.34758</td>\n",
       "      <td>1.518731e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x97aeb9b292c00405e145d9c7a8429bc970fa0e65</td>\n",
       "      <td>0x4f00b95c625c6d6ef72748d78c750fd6c84a8b85</td>\n",
       "      <td>0.01003</td>\n",
       "      <td>1.516224e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2dfdf31bbc29468d487591f292872a14c1f8d1f0</td>\n",
       "      <td>0x474057adf42f9f955e86aa1142740f9d7763e41e</td>\n",
       "      <td>0.51587</td>\n",
       "      <td>1.522422e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x5b39067ee0309856edd13f23c9c1793f9fda1b4f</td>\n",
       "      <td>0x6376baf58c4c5d70ba8fca9565b6955f07c584a9</td>\n",
       "      <td>6.67000</td>\n",
       "      <td>1.514817e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          src  \\\n",
       "0  0x21f74c6bbc1e3ab9f0205e12de3a9daa14351aed   \n",
       "1  0x54008c2684d96c44a094dc127842ec144b157e96   \n",
       "2  0x97aeb9b292c00405e145d9c7a8429bc970fa0e65   \n",
       "3  0x2dfdf31bbc29468d487591f292872a14c1f8d1f0   \n",
       "4  0x5b39067ee0309856edd13f23c9c1793f9fda1b4f   \n",
       "\n",
       "                                          dst   amount     timestamp  \n",
       "0  0x46f1c0481803cb34a7860d614b5430c5db51bfb7  5.00000  1.502740e+09  \n",
       "1  0x1acee83486b6671b005eed45c9fb9277e7eeb63d  2.34758  1.518731e+09  \n",
       "2  0x4f00b95c625c6d6ef72748d78c750fd6c84a8b85  0.01003  1.516224e+09  \n",
       "3  0x474057adf42f9f955e86aa1142740f9d7763e41e  0.51587  1.522422e+09  \n",
       "4  0x6376baf58c4c5d70ba8fca9565b6955f07c584a9  6.67000  1.514817e+09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_df = pd.read_csv(ACCOUNTS_CSV, header=None, names=['id', 'label'])\n",
    "tx_df  = pd.read_csv(TXS_CSV, header=None, names=['src', 'dst', 'amount', 'timestamp'])\n",
    "\n",
    "display(acc_df.head())\n",
    "display(tx_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66514556",
   "metadata": {},
   "source": [
    "## 🏗️ Сборка графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b4cfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Граф содержит 32,168 узлов и 42,044 рёбер\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "for _, row in acc_df.iterrows():\n",
    "    G.add_node(row.id, label=int(bool(row.label)))\n",
    "\n",
    "# add edges\n",
    "for _, row in tx_df.iterrows():\n",
    "    G.add_edge(row.src, row.dst, amount=float(row.amount), ts=float(row.timestamp))\n",
    "\n",
    "print(f'Граф содержит {G.number_of_nodes():,} узлов и {G.number_of_edges():,} рёбер')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2df1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Calculating extra graph features…\n"
     ]
    }
   ],
   "source": [
    "# Структурные признаки\n",
    "in_deg  = dict(G.in_degree())\n",
    "out_deg = dict(G.out_degree())\n",
    "\n",
    "# Финансовые суммы\n",
    "sent_sum = {n: 0.0 for n in G.nodes()}\n",
    "recv_sum = {n: 0.0 for n in G.nodes()}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    amt = d['amount']\n",
    "    sent_sum[u] += amt\n",
    "    recv_sum[v] += amt\n",
    "\n",
    "# PageRank и кластерный коэффициент\n",
    "pr = nx.pagerank(G, alpha=0.85)\n",
    "clust = nx.clustering(G.to_undirected())\n",
    "\n",
    "# Записываем фичи в граф\n",
    "for n in G.nodes():\n",
    "    G.nodes[n].update({\n",
    "        'in_deg':      in_deg.get(n, 0),\n",
    "        'out_deg':     out_deg.get(n, 0),\n",
    "        'sent_sum':    sent_sum[n],\n",
    "        'recv_sum':    recv_sum[n],\n",
    "        'net_sum':     sent_sum[n] - recv_sum[n],\n",
    "        'pagerank':    pr[n],\n",
    "        'clustering':  clust[n],\n",
    "    })\n",
    "\n",
    "# --- после расчёта pr и clust --------------------------------------------\n",
    "print('⏳ Calculating extra graph features…')\n",
    "\n",
    "# 1) Betweenness (approx)\n",
    "btw = nx.betweenness_centrality(G, k=10_000, seed=42, normalized=True)\n",
    "\n",
    "# 2) Weakly-connected component size\n",
    "G_u = G.to_undirected()\n",
    "wcc = {n: 0 for n in G}\n",
    "for comp in nx.connected_components(G_u):\n",
    "    size = len(comp)\n",
    "    for n in comp:\n",
    "        wcc[n] = size\n",
    "\n",
    "# 3) Min amounts\n",
    "send_min = {n: math.inf for n in G}\n",
    "recv_min = {n: math.inf for n in G}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    amt = d['amount']\n",
    "    send_min[u] = min(send_min[u], amt)\n",
    "    recv_min[v] = min(recv_min[v], amt)\n",
    "# заменяем inf → 0.0 (узлы без операций)\n",
    "send_min = {n: 0.0 if math.isinf(v) else v for n, v in send_min.items()}\n",
    "recv_min = {n: 0.0 if math.isinf(v) else v for n, v in recv_min.items()}\n",
    "\n",
    "# --- записываем все новые фичи в вершины ----------------------------------\n",
    "for n in G.nodes():\n",
    "    G.nodes[n].update({\n",
    "        'btw_centr':   btw[n],\n",
    "        'wcc_size':    wcc[n],\n",
    "        'send_min':    send_min[n],\n",
    "        'recv_min':    recv_min[n],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ebfeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Training Node2Vec…\n",
      "Epoch 1, Loss 245.9309\n"
     ]
    }
   ],
   "source": [
    " # --- перед обучением Node2Vec: создаём маппинг id → idx -------------------\n",
    "id2idx = {n: i for i, n in enumerate(G.nodes())}\n",
    "\n",
    "# --- строим edge_index по числовым индексам ------------------------------\n",
    "edges = list(G.edges())\n",
    "row = [id2idx[u] for u, v in edges]\n",
    "col = [id2idx[v] for u, v in edges]\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index).contiguous()\n",
    "\n",
    "# --- теперь обучаем Node2Vec на неориентированном графе --------------------\n",
    "print('⏳ Training Node2Vec…')\n",
    "n2v = Node2Vec(\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=G.number_of_nodes(),\n",
    "    embedding_dim=128,\n",
    "    walk_length=20,\n",
    "    context_size=10,\n",
    "    walks_per_node=5,\n",
    "    num_negative_samples=1,\n",
    "    sparse=True,\n",
    "    p=1, q=1\n",
    ").to(device)\n",
    "\n",
    "loader = n2v.loader(batch_size=1024, shuffle=True)\n",
    "opt = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "n2v.train()\n",
    "for epoch in range(1):  # можете увеличить число эпох\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        opt.zero_grad()\n",
    "        loss = n2v.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss {total_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c44daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример фич узла: ('0x8335392fe1b236296c5d5f653264396de165e46c', {'label': 1, 'in_deg': 4, 'out_deg': 1, 'sent_sum': 3.49954, 'recv_sum': 3.4999599999999997, 'net_sum': -0.0004199999999996429, 'pagerank': 4.475874254314406e-05, 'clustering': 0, 'btw_centr': 0.0, 'wcc_size': 30701, 'send_min': 3.49954, 'recv_min': 0.5, 'n2v': tensor([ 6.8942e-01,  8.5973e-01,  1.0686e+00,  1.4085e+00,  1.0570e+00,\n",
      "        -1.4657e+00, -1.3695e-01,  1.0924e+00,  1.0840e+00,  7.2765e-01,\n",
      "         1.1007e+00,  4.2189e-01, -1.0614e-02,  8.4886e-01,  8.8466e-03,\n",
      "         3.1550e-01,  2.9505e+00,  8.3457e-01, -1.3613e+00, -2.7187e-01,\n",
      "         1.1702e+00,  6.5422e-01,  1.1230e+00,  9.5035e-01, -4.9182e-01,\n",
      "        -1.0446e-01, -1.2157e+00, -3.3540e-01, -9.3921e-03,  9.2506e-01,\n",
      "         1.0898e-01,  2.1533e-01, -1.1534e-01, -6.5742e-01, -3.7616e-01,\n",
      "        -6.1318e-01,  4.2779e-02,  1.8825e-01,  7.5775e-01, -4.5954e-01,\n",
      "         3.8189e-01, -1.6699e-01, -5.5390e-01, -1.9875e+00, -5.5424e-01,\n",
      "         9.2062e-01, -3.8111e-01, -5.2600e-01,  8.2198e-01, -8.4987e-01,\n",
      "        -2.5334e-01,  1.1870e+00, -6.9856e-01,  2.0712e-03,  4.2113e-01,\n",
      "        -5.9494e-01,  6.8562e-01, -4.2178e-02,  1.2529e+00,  1.9859e+00,\n",
      "         1.9541e+00,  1.6522e+00,  5.5268e-01,  7.8486e-01, -1.4180e+00,\n",
      "         4.3562e-01, -1.1362e-01, -1.2418e-01,  5.4959e-02,  3.1989e-01,\n",
      "         1.4164e+00, -9.5775e-01,  1.3309e+00, -1.2775e+00, -9.8282e-01,\n",
      "        -6.8607e-01, -7.8173e-01,  4.3187e-01,  2.9037e-01,  8.5128e-01,\n",
      "         1.4929e+00,  5.5632e-02,  1.1908e+00, -7.6823e-01,  1.3592e+00,\n",
      "         8.9812e-01, -1.2902e+00,  9.1188e-01,  9.3626e-02, -6.8855e-01,\n",
      "         9.6456e-01,  1.9287e+00, -1.2114e+00, -5.7441e-01, -1.3469e-01,\n",
      "         3.2150e-01,  8.1109e-01,  7.5696e-01,  1.2131e+00,  6.2165e-01,\n",
      "         2.5694e-01, -7.8932e-01,  4.1934e-01, -1.8073e+00,  8.3873e-01,\n",
      "         5.4111e-01,  3.0693e-01,  2.2461e+00, -1.8583e+00, -7.7057e-01,\n",
      "         1.8089e+00,  1.0680e+00,  3.1424e+00, -7.2122e-01,  1.3487e+00,\n",
      "        -9.1857e-01, -4.0777e-01,  6.3115e-01, -2.2433e-01,  5.9044e-01,\n",
      "         1.4139e+00,  4.7748e-01,  1.7214e+00, -3.0105e-01, -9.2869e-01,\n",
      "        -6.2712e-01, -1.1221e+00, -8.0636e-01]), 'x': tensor([ 4.0000e+00,  1.0000e+00,  3.4995e+00,  3.5000e+00, -4.2000e-04,\n",
      "         4.4759e-05,  0.0000e+00,  0.0000e+00,  3.0701e+04,  3.4995e+00,\n",
      "         5.0000e-01,  6.8942e-01,  8.5973e-01,  1.0686e+00,  1.4085e+00,\n",
      "         1.0570e+00, -1.4657e+00, -1.3695e-01,  1.0924e+00,  1.0840e+00,\n",
      "         7.2765e-01,  1.1007e+00,  4.2189e-01, -1.0614e-02,  8.4886e-01,\n",
      "         8.8466e-03,  3.1550e-01,  2.9505e+00,  8.3457e-01, -1.3613e+00,\n",
      "        -2.7187e-01,  1.1702e+00,  6.5422e-01,  1.1230e+00,  9.5035e-01,\n",
      "        -4.9182e-01, -1.0446e-01, -1.2157e+00, -3.3540e-01, -9.3921e-03,\n",
      "         9.2506e-01,  1.0898e-01,  2.1533e-01, -1.1534e-01, -6.5742e-01,\n",
      "        -3.7616e-01, -6.1318e-01,  4.2779e-02,  1.8825e-01,  7.5775e-01,\n",
      "        -4.5954e-01,  3.8189e-01, -1.6699e-01, -5.5390e-01, -1.9875e+00,\n",
      "        -5.5424e-01,  9.2062e-01, -3.8111e-01, -5.2600e-01,  8.2198e-01,\n",
      "        -8.4987e-01, -2.5334e-01,  1.1870e+00, -6.9856e-01,  2.0712e-03,\n",
      "         4.2113e-01, -5.9494e-01,  6.8562e-01, -4.2178e-02,  1.2529e+00,\n",
      "         1.9859e+00,  1.9541e+00,  1.6522e+00,  5.5268e-01,  7.8486e-01,\n",
      "        -1.4180e+00,  4.3562e-01, -1.1362e-01, -1.2418e-01,  5.4959e-02,\n",
      "         3.1989e-01,  1.4164e+00, -9.5775e-01,  1.3309e+00, -1.2775e+00,\n",
      "        -9.8282e-01, -6.8607e-01, -7.8173e-01,  4.3187e-01,  2.9037e-01,\n",
      "         8.5128e-01,  1.4929e+00,  5.5632e-02,  1.1908e+00, -7.6823e-01,\n",
      "         1.3592e+00,  8.9812e-01, -1.2902e+00,  9.1188e-01,  9.3626e-02,\n",
      "        -6.8855e-01,  9.6456e-01,  1.9287e+00, -1.2114e+00, -5.7441e-01,\n",
      "        -1.3469e-01,  3.2150e-01,  8.1109e-01,  7.5696e-01,  1.2131e+00,\n",
      "         6.2165e-01,  2.5694e-01, -7.8932e-01,  4.1934e-01, -1.8073e+00,\n",
      "         8.3873e-01,  5.4111e-01,  3.0693e-01,  2.2461e+00, -1.8583e+00,\n",
      "        -7.7057e-01,  1.8089e+00,  1.0680e+00,  3.1424e+00, -7.2122e-01,\n",
      "         1.3487e+00, -9.1857e-01, -4.0777e-01,  6.3115e-01, -2.2433e-01,\n",
      "         5.9044e-01,  1.4139e+00,  4.7748e-01,  1.7214e+00, -3.0105e-01,\n",
      "        -9.2869e-01, -6.2712e-01, -1.1221e+00, -8.0636e-01])})\n"
     ]
    }
   ],
   "source": [
    "# --- извлекаем эмбеддинги и записываем обратно в G ------------------------\n",
    "z = n2v.embedding.weight.detach().cpu()\n",
    "for n, idx in id2idx.items():\n",
    "    G.nodes[n]['n2v'] = z[idx]\n",
    "\n",
    "# --- при формировании data.x ---------------------------------------------\n",
    "num_attr_keys = [\n",
    "    'in_deg','out_deg','sent_sum','recv_sum','net_sum',\n",
    "    'pagerank','clustering',\n",
    "    'btw_centr','wcc_size','send_min','recv_min'\n",
    "]\n",
    "\n",
    "for n in G.nodes():\n",
    "    base = [float(G.nodes[n][k]) for k in num_attr_keys]\n",
    "    emb  = G.nodes[n]['n2v'].tolist()           # 128-мерный\n",
    "    G.nodes[n]['x'] = torch.tensor(base + emb, dtype=torch.float)\n",
    "\n",
    "print('Пример фич узла:', list(G.nodes(data=True))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5433d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Делаем так, чтобы у всех узлов была метка\n",
    "nx.set_node_attributes(G, -1, \"label\")        # сначала всем ставим -1\n",
    "for _, row in acc_df.iterrows():              # затем переопределяем тем, что есть в accounts.csv\n",
    "    G.nodes[row.id][\"label\"] = int(bool(row.label))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd60dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# после формирования всех численных признаков, до отправки в PyG\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.stack([G.nodes[n]['x'].numpy() for n in G.nodes()])\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "for n, vec in zip(G.nodes(), X):\n",
    "    G.nodes[n]['x'] = torch.tensor(vec, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4c1f2",
   "metadata": {},
   "source": [
    "## 🔄 Конвертация в `torch_geometric.data.Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a06745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 42044], label=[32168], in_deg=[32168], out_deg=[32168], sent_sum=[32168], recv_sum=[32168], net_sum=[32168], pagerank=[32168], clustering=[32168], btw_centr=[32168], wcc_size=[32168], send_min=[32168], recv_min=[32168], n2v=[32168, 128], amount=[42044], ts=[42044], x=[32168, 7], y=[32168])\n"
     ]
    }
   ],
   "source": [
    "num_attr_keys = ['in_deg','out_deg','sent_sum','recv_sum','net_sum','pagerank','clustering']\n",
    "\n",
    "for n in G.nodes():\n",
    "    G.nodes[n]['x'] = torch.tensor([float(G.nodes[n][k]) for k in num_attr_keys], dtype=torch.float)\n",
    "\n",
    "data = from_networkx(G, group_node_attrs=['x'])\n",
    "data.y = torch.tensor([G.nodes[n].get('label', -1) for n in G.nodes()], dtype=torch.long)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cd688",
   "metadata": {},
   "source": [
    "## ✂️ Train / Val / Test сплит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f9609b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 19300, Val: 6433, Test: 6435\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "N = data.num_nodes\n",
    "perm = torch.randperm(N)\n",
    "n_train = int(0.6 * N)\n",
    "n_val   = int(0.2 * N)\n",
    "\n",
    "data.train_mask = torch.zeros(N, dtype=torch.bool)\n",
    "data.val_mask   = torch.zeros(N, dtype=torch.bool)\n",
    "data.test_mask  = torch.zeros(N, dtype=torch.bool)\n",
    "\n",
    "data.train_mask[perm[:n_train]]           = True\n",
    "data.val_mask[perm[n_train:n_train+n_val]] = True\n",
    "data.test_mask[perm[n_train+n_val:]]      = True\n",
    "\n",
    "print(f'Train: {data.train_mask.sum().item()}, Val: {data.val_mask.sum().item()}, Test: {data.test_mask.sum().item()}')\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.train_mask,        # корневые узлы для train\n",
    "    num_neighbors=[25, 15],             # сколько соседей на каждом слое\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.val_mask,\n",
    "    num_neighbors=[25, 15],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.test_mask,\n",
    "    num_neighbors=[25, 15],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1143320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сериализовано в /Users/a1234/Fraud/gnn/artifacts/eth_graph.pt\n"
     ]
    }
   ],
   "source": [
    "OUT_PATH = Path('./artifacts/eth_graph.pt')\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(data, OUT_PATH)\n",
    "print(f'Сериализовано в {OUT_PATH.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e9339",
   "metadata": {},
   "source": [
    "## 🧠 Определение GNN‑модели (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7823c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "# 1) Определяем GraphSAGE\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee4b5e",
   "metadata": {},
   "source": [
    "## 🏃‍♂️ Обучение и валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bc6b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: normal=1.00, fraud=1.72\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m51\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m eval_loader(train_loader)\n\u001b[1;32m     45\u001b[0m     val_acc   \u001b[38;5;241m=\u001b[39m eval_loader(val_loader)\n",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     17\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     19\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/torch_geometric/loader/node_loader.py:147\u001b[0m, in \u001b[0;36mNodeLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m input_data: NodeSamplerInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data[index]\n\u001b[0;32m--> 147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_per_worker:  \u001b[38;5;66;03m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:322\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_nodes\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample_from_nodes\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    320\u001b[0m     inputs: NodeSamplerInput,\n\u001b[1;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 322\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnode_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubgraph_type \u001b[38;5;241m==\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39mbidirectional:\n\u001b[1;32m    324\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto_bidirectional()\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:542\u001b[0m, in \u001b[0;36mnode_sample\u001b[0;34m(inputs, sample_fn)\u001b[0m\n\u001b[1;32m    539\u001b[0m     seed \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnode\n\u001b[1;32m    540\u001b[0m     seed_time \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtime\n\u001b[0;32m--> 542\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m out\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m (inputs\u001b[38;5;241m.\u001b[39minput_id, inputs\u001b[38;5;241m.\u001b[39mtime)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:508\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     num_sampled_nodes \u001b[38;5;241m=\u001b[39m num_sampled_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-sparse\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SamplerOutput(\n\u001b[1;32m    512\u001b[0m     node\u001b[38;5;241m=\u001b[39mnode,\n\u001b[1;32m    513\u001b[0m     row\u001b[38;5;241m=\u001b[39mrow,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m     num_sampled_edges\u001b[38;5;241m=\u001b[39mnum_sampled_edges,\n\u001b[1;32m    519\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "labels = data.y[data.y != -1]\n",
    "counts = torch.bincount(labels)\n",
    "weight = torch.tensor([1.0, counts[0].float() / counts[1].float()], device=device)\n",
    "print(f\"Class weights: normal={weight[0]:.2f}, fraud={weight[1]:.2f}\")\n",
    "\n",
    "# 3) Инициализируем модель, optimizer, criterion (с весами из шага 2)\n",
    "model = GraphSAGE(data.num_node_features, 64, int(data.y.max().item())+1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "# 4) Цикл обучения\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        # только первые batch.batch_size предсказаний — для корневых узлов\n",
    "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.batch_size\n",
    "    return total_loss / int(data.train_mask.sum())\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        preds = out[:batch.batch_size].argmax(dim=1)\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        correct += int((preds == y).sum())\n",
    "        total   += batch.batch_size\n",
    "    return correct / total\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train_epoch()\n",
    "    train_acc = eval_loader(train_loader)\n",
    "    val_acc   = eval_loader(val_loader)\n",
    "    print(f'Epoch {epoch:02d} | Loss {loss:.4f} | Train Acc {train_acc:.3f} | Val Acc {val_acc:.3f}')\n",
    "\n",
    "test_acc = eval_loader(test_loader)\n",
    "print(f'✅ Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115f6d0",
   "metadata": {},
   "source": [
    "## 📊 Визуализация результатов\n",
    "Вычислим метрики на тестовой выборке и отобразим матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.894     0.839     0.865       410\n",
      "           1      0.735     0.817     0.774       224\n",
      "\n",
      "    accuracy                          0.831       634\n",
      "   macro avg      0.814     0.828     0.820       634\n",
      "weighted avg      0.837     0.831     0.833       634\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "logits = model(data.x, data.edge_index)\n",
    "preds  = logits.argmax(dim=1)\n",
    "\n",
    "mask = (data.test_mask) & (data.y != -1)\n",
    "y_true, y_pred = data.y[mask].cpu(), preds[mask].cpu()\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix (Test)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f0a29",
   "metadata": {},
   "source": [
    "## 🕵️‍♂️ Интерпретация предсказаний с **GNNExplainer**\n",
    "Выберем произвольный корректно классифицированный узел из тестовой выборки и посмотрим, какие рёбра и признаки были наиболее важны для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e96cf",
   "metadata": {},
   "source": [
    "## 💾 Сохранение обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b195ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в /Users/a1234/Fraud/gnn/checkpoints/gcn_model.pt\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = Path('./checkpoints/gcn_model.pt')\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f'Модель сохранена в {MODEL_PATH.resolve()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
