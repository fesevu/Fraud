{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ab3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.3.0\n",
      "Uninstalling torch-2.3.0:\n",
      "  Successfully uninstalled torch-2.3.0\n",
      "Found existing installation: torch-geometric 2.6.1\n",
      "Uninstalling torch-geometric-2.6.1:\n",
      "  Successfully uninstalled torch-geometric-2.6.1\n",
      "\u001b[33mWARNING: Skipping torch_scatter as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_sparse as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pyg_lib as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_cluster as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch_spline_conv as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch==2.3.0\n",
      "  Using cached torch-2.3.0-cp39-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (4.13.2)\n",
      "Requirement already satisfied: sympy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch==2.3.0) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from sympy->torch==2.3.0) (1.3.0)\n",
      "Using cached torch-2.3.0-cp39-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (3.11.18)\n",
      "Requirement already satisfied: fsspec in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from requests->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from requests->torch_geometric) (2025.4.26)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
      "Collecting torch_scatter\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_scatter-2.1.2-cp39-cp39-macosx_10_9_universal2.whl (555 kB)\n",
      "Collecting torch_sparse\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_sparse-0.6.18-cp39-cp39-macosx_11_0_universal2.whl (556 kB)\n",
      "Collecting torch_cluster\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_cluster-1.6.3-cp39-cp39-macosx_10_9_universal2.whl (600 kB)\n",
      "Collecting torch_spline_conv\n",
      "  Using cached https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_spline_conv-1.2.2-cp39-cp39-macosx_10_9_universal2.whl (206 kB)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from torch_sparse) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from scipy->torch_sparse) (2.0.2)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, torch_sparse, torch_cluster\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torch_cluster]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch_cluster-1.6.3 torch_scatter-2.1.2 torch_sparse-0.6.18 torch_spline_conv-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: pandas in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: graphviz in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (0.20.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (3.2.1)\n",
      "Requirement already satisfied: seaborn in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a1234/Fraud/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall torch torch_geometric torch_scatter torch_sparse pyg_lib torch_cluster torch_spline_conv -y\n",
    "# 2.1 PyTorch (CPU) – подмените индекс, если нужна CUDA\n",
    "%pip install torch==2.3.0\n",
    "\n",
    "# 2.2 PyG: с 2.3+ внешних библиотек почти нет, ставим одной строкой\n",
    "%pip install torch_geometric\n",
    "%pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
    "\n",
    "\n",
    "# 2.4 остальное\n",
    "%pip install xgboost pandas matplotlib graphviz scikit-learn tqdm numpy networkx seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f797bd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.utils import to_undirected\n",
    "import math\n",
    "import torch_cluster\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb6648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36105035",
   "metadata": {},
   "source": [
    "# Чтение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7636f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ACCOUNTS_CSV = Path('./tmp/Ethereum/account.csv')      # обновите при необходимости\n",
    "TXS_CSV      = Path('./tmp/Ethereum/transaction.csv')   # обновите при необходимости\n",
    "\n",
    "assert ACCOUNTS_CSV.exists(), f'{ACCOUNTS_CSV} not found'\n",
    "assert TXS_CSV.exists(), f'{TXS_CSV} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f88c6572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x8335392fe1b236296c5d5f653264396de165e46c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x9d4b62503b4b7993182323effe6245f6d77e4413</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc91293245b669da19a96cd85d40bb9c203359657</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1056d8d9ebb0e0d8710a0e2a1852d4a09d56464a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x4f1872383be22878af5d4795b69be61b35ec5d10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id  label\n",
       "0  0x8335392fe1b236296c5d5f653264396de165e46c   True\n",
       "1  0x9d4b62503b4b7993182323effe6245f6d77e4413   True\n",
       "2  0xc91293245b669da19a96cd85d40bb9c203359657   True\n",
       "3  0x1056d8d9ebb0e0d8710a0e2a1852d4a09d56464a   True\n",
       "4  0x4f1872383be22878af5d4795b69be61b35ec5d10   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x21f74c6bbc1e3ab9f0205e12de3a9daa14351aed</td>\n",
       "      <td>0x46f1c0481803cb34a7860d614b5430c5db51bfb7</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.502740e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x54008c2684d96c44a094dc127842ec144b157e96</td>\n",
       "      <td>0x1acee83486b6671b005eed45c9fb9277e7eeb63d</td>\n",
       "      <td>2.34758</td>\n",
       "      <td>1.518731e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x97aeb9b292c00405e145d9c7a8429bc970fa0e65</td>\n",
       "      <td>0x4f00b95c625c6d6ef72748d78c750fd6c84a8b85</td>\n",
       "      <td>0.01003</td>\n",
       "      <td>1.516224e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2dfdf31bbc29468d487591f292872a14c1f8d1f0</td>\n",
       "      <td>0x474057adf42f9f955e86aa1142740f9d7763e41e</td>\n",
       "      <td>0.51587</td>\n",
       "      <td>1.522422e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x5b39067ee0309856edd13f23c9c1793f9fda1b4f</td>\n",
       "      <td>0x6376baf58c4c5d70ba8fca9565b6955f07c584a9</td>\n",
       "      <td>6.67000</td>\n",
       "      <td>1.514817e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          src  \\\n",
       "0  0x21f74c6bbc1e3ab9f0205e12de3a9daa14351aed   \n",
       "1  0x54008c2684d96c44a094dc127842ec144b157e96   \n",
       "2  0x97aeb9b292c00405e145d9c7a8429bc970fa0e65   \n",
       "3  0x2dfdf31bbc29468d487591f292872a14c1f8d1f0   \n",
       "4  0x5b39067ee0309856edd13f23c9c1793f9fda1b4f   \n",
       "\n",
       "                                          dst   amount     timestamp  \n",
       "0  0x46f1c0481803cb34a7860d614b5430c5db51bfb7  5.00000  1.502740e+09  \n",
       "1  0x1acee83486b6671b005eed45c9fb9277e7eeb63d  2.34758  1.518731e+09  \n",
       "2  0x4f00b95c625c6d6ef72748d78c750fd6c84a8b85  0.01003  1.516224e+09  \n",
       "3  0x474057adf42f9f955e86aa1142740f9d7763e41e  0.51587  1.522422e+09  \n",
       "4  0x6376baf58c4c5d70ba8fca9565b6955f07c584a9  6.67000  1.514817e+09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_df = pd.read_csv(ACCOUNTS_CSV, header=None, names=['id', 'label'])\n",
    "tx_df  = pd.read_csv(TXS_CSV, header=None, names=['src', 'dst', 'amount', 'timestamp'])\n",
    "\n",
    "display(acc_df.head())\n",
    "display(tx_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66514556",
   "metadata": {},
   "source": [
    "## 🏗️ Сборка графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48b4cfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Граф содержит 32,168 узлов и 42,044 рёбер\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "for _, row in acc_df.iterrows():\n",
    "    G.add_node(row.id, label=int(bool(row.label)))\n",
    "\n",
    "# add edges\n",
    "for _, row in tx_df.iterrows():\n",
    "    G.add_edge(row.src, row.dst, amount=float(row.amount), ts=float(row.timestamp))\n",
    "\n",
    "print(f'Граф содержит {G.number_of_nodes():,} узлов и {G.number_of_edges():,} рёбер')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2df1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Calculating extra graph features…\n"
     ]
    }
   ],
   "source": [
    "# Структурные признаки\n",
    "in_deg  = dict(G.in_degree())\n",
    "out_deg = dict(G.out_degree())\n",
    "\n",
    "# Финансовые суммы\n",
    "sent_sum = {n: 0.0 for n in G.nodes()}\n",
    "recv_sum = {n: 0.0 for n in G.nodes()}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    amt = d['amount']\n",
    "    sent_sum[u] += amt\n",
    "    recv_sum[v] += amt\n",
    "\n",
    "# PageRank и кластерный коэффициент\n",
    "pr = nx.pagerank(G, alpha=0.85)\n",
    "clust = nx.clustering(G.to_undirected())\n",
    "\n",
    "# Записываем фичи в граф\n",
    "for n in G.nodes():\n",
    "    G.nodes[n].update({\n",
    "        'in_deg':      in_deg.get(n, 0),\n",
    "        'out_deg':     out_deg.get(n, 0),\n",
    "        'sent_sum':    sent_sum[n],\n",
    "        'recv_sum':    recv_sum[n],\n",
    "        'net_sum':     sent_sum[n] - recv_sum[n],\n",
    "        'pagerank':    pr[n],\n",
    "        'clustering':  clust[n],\n",
    "    })\n",
    "\n",
    "# --- после расчёта pr и clust --------------------------------------------\n",
    "print('⏳ Calculating extra graph features…')\n",
    "\n",
    "# 1) Betweenness (approx)\n",
    "btw = nx.betweenness_centrality(G, k=10_000, seed=42, normalized=True)\n",
    "\n",
    "# 2) Weakly-connected component size\n",
    "G_u = G.to_undirected()\n",
    "wcc = {n: 0 for n in G}\n",
    "for comp in nx.connected_components(G_u):\n",
    "    size = len(comp)\n",
    "    for n in comp:\n",
    "        wcc[n] = size\n",
    "\n",
    "# 3) Min amounts\n",
    "send_min = {n: math.inf for n in G}\n",
    "recv_min = {n: math.inf for n in G}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    amt = d['amount']\n",
    "    send_min[u] = min(send_min[u], amt)\n",
    "    recv_min[v] = min(recv_min[v], amt)\n",
    "# заменяем inf → 0.0 (узлы без операций)\n",
    "send_min = {n: 0.0 if math.isinf(v) else v for n, v in send_min.items()}\n",
    "recv_min = {n: 0.0 if math.isinf(v) else v for n, v in recv_min.items()}\n",
    "\n",
    "# --- записываем все новые фичи в вершины ----------------------------------\n",
    "for n in G.nodes():\n",
    "    G.nodes[n].update({\n",
    "        'btw_centr':   btw[n],\n",
    "        'wcc_size':    wcc[n],\n",
    "        'send_min':    send_min[n],\n",
    "        'recv_min':    recv_min[n],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebfeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Training Node2Vec…\n",
      "Epoch 1, Loss 246.0344\n",
      "Epoch 2, Loss 185.5990\n",
      "Epoch 3, Loss 150.2787\n",
      "Epoch 4, Loss 122.1331\n",
      "Epoch 5, Loss 99.6138\n"
     ]
    }
   ],
   "source": [
    " # --- перед обучением Node2Vec: создаём маппинг id → idx -------------------\n",
    "id2idx = {n: i for i, n in enumerate(G.nodes())}\n",
    "\n",
    "# --- строим edge_index по числовым индексам ------------------------------\n",
    "edges = list(G.edges())\n",
    "row = [id2idx[u] for u, v in edges]\n",
    "col = [id2idx[v] for u, v in edges]\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index).contiguous()\n",
    "\n",
    "# --- теперь обучаем Node2Vec на неориентированном графе --------------------\n",
    "print('⏳ Training Node2Vec…')\n",
    "n2v = Node2Vec(\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=G.number_of_nodes(),\n",
    "    embedding_dim=128,\n",
    "    walk_length=20,\n",
    "    context_size=10,\n",
    "    walks_per_node=5,\n",
    "    num_negative_samples=1,\n",
    "    sparse=True,\n",
    "    p=1, q=1\n",
    ").to(device)\n",
    "\n",
    "loader = n2v.loader(batch_size=1024, shuffle=True)\n",
    "opt = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
    "\n",
    "n2v.train()\n",
    "for epoch in range(40):  # можете увеличить число эпох\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        opt.zero_grad()\n",
    "        loss = n2v.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss {total_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c44daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример фич узла: ('0x8335392fe1b236296c5d5f653264396de165e46c', {'label': 1, 'in_deg': 4, 'out_deg': 1, 'sent_sum': 3.49954, 'recv_sum': 3.4999599999999997, 'net_sum': -0.0004199999999996429, 'pagerank': 4.475874254314406e-05, 'clustering': 0, 'btw_centr': 0.0, 'wcc_size': 30701, 'send_min': 3.49954, 'recv_min': 0.5, 'n2v': tensor([-0.3263, -0.9942, -0.4803,  0.5377, -0.5554, -0.6436,  0.5854, -0.8306,\n",
      "         0.4574,  0.8498,  1.2007, -1.0742, -0.5128, -0.3223, -0.0596, -0.1528,\n",
      "         0.9123,  0.5771,  0.8630,  1.2475, -0.4094, -0.5058, -0.5839, -1.5232,\n",
      "        -0.4698, -0.3420,  0.9764,  0.1384, -0.5216, -0.3267,  0.4469, -0.4312,\n",
      "         0.1008, -1.3053,  0.7192, -1.2030,  0.0521, -0.1258,  0.6617,  0.0397,\n",
      "        -0.6533, -0.6969, -0.6242, -0.0925,  0.2065,  0.6458,  0.6187,  0.5766,\n",
      "         1.0146,  0.9408,  0.5583,  0.5236, -0.3055,  0.9530, -0.2336, -0.7888,\n",
      "        -1.3516,  0.7423,  0.7200,  0.6539,  0.5183,  0.2476,  0.2971, -0.5402,\n",
      "        -0.7539,  0.5327,  0.2945,  0.2118, -0.4394,  0.7294,  0.0765, -0.6604,\n",
      "        -0.4716,  0.9292, -1.7458, -0.2163, -1.5390,  0.4313, -0.3803, -0.6656,\n",
      "         0.6118, -0.6845, -0.0481,  0.0955, -1.3548,  0.3945, -1.1022, -0.7895,\n",
      "         1.0226, -0.7264,  0.1274,  1.5636, -0.1402, -0.0279,  0.6717,  0.0756,\n",
      "        -1.6913,  1.1608, -2.1397,  0.8735, -0.1010,  0.4316,  0.6063, -1.4522,\n",
      "         0.7987, -1.2305,  0.4260,  0.1482,  0.1372, -0.5678,  1.6804,  0.2843,\n",
      "         0.0851, -1.1955, -1.7678,  0.6235,  0.3008, -1.1160,  0.7538,  0.4405,\n",
      "        -1.2386, -0.7804, -1.0747, -0.7735,  0.4157, -1.3152,  0.4489, -1.3814]), 'x': tensor([ 4.0000e+00,  1.0000e+00,  3.4995e+00,  3.5000e+00, -4.2000e-04,\n",
      "         4.4759e-05,  0.0000e+00,  0.0000e+00,  3.0701e+04,  3.4995e+00,\n",
      "         5.0000e-01, -3.2634e-01, -9.9416e-01, -4.8025e-01,  5.3774e-01,\n",
      "        -5.5543e-01, -6.4363e-01,  5.8538e-01, -8.3065e-01,  4.5737e-01,\n",
      "         8.4977e-01,  1.2007e+00, -1.0742e+00, -5.1282e-01, -3.2226e-01,\n",
      "        -5.9591e-02, -1.5277e-01,  9.1232e-01,  5.7713e-01,  8.6297e-01,\n",
      "         1.2475e+00, -4.0944e-01, -5.0577e-01, -5.8387e-01, -1.5232e+00,\n",
      "        -4.6978e-01, -3.4200e-01,  9.7636e-01,  1.3835e-01, -5.2155e-01,\n",
      "        -3.2671e-01,  4.4686e-01, -4.3124e-01,  1.0085e-01, -1.3053e+00,\n",
      "         7.1919e-01, -1.2030e+00,  5.2142e-02, -1.2579e-01,  6.6175e-01,\n",
      "         3.9725e-02, -6.5328e-01, -6.9692e-01, -6.2423e-01, -9.2545e-02,\n",
      "         2.0654e-01,  6.4582e-01,  6.1867e-01,  5.7658e-01,  1.0146e+00,\n",
      "         9.4077e-01,  5.5833e-01,  5.2360e-01, -3.0549e-01,  9.5300e-01,\n",
      "        -2.3358e-01, -7.8878e-01, -1.3516e+00,  7.4235e-01,  7.2003e-01,\n",
      "         6.5390e-01,  5.1832e-01,  2.4759e-01,  2.9709e-01, -5.4023e-01,\n",
      "        -7.5392e-01,  5.3274e-01,  2.9453e-01,  2.1183e-01, -4.3939e-01,\n",
      "         7.2941e-01,  7.6488e-02, -6.6044e-01, -4.7161e-01,  9.2924e-01,\n",
      "        -1.7458e+00, -2.1633e-01, -1.5390e+00,  4.3133e-01, -3.8035e-01,\n",
      "        -6.6558e-01,  6.1180e-01, -6.8449e-01, -4.8065e-02,  9.5483e-02,\n",
      "        -1.3548e+00,  3.9452e-01, -1.1022e+00, -7.8952e-01,  1.0226e+00,\n",
      "        -7.2641e-01,  1.2745e-01,  1.5636e+00, -1.4022e-01, -2.7914e-02,\n",
      "         6.7166e-01,  7.5606e-02, -1.6913e+00,  1.1608e+00, -2.1397e+00,\n",
      "         8.7351e-01, -1.0098e-01,  4.3158e-01,  6.0630e-01, -1.4522e+00,\n",
      "         7.9868e-01, -1.2305e+00,  4.2598e-01,  1.4818e-01,  1.3715e-01,\n",
      "        -5.6785e-01,  1.6804e+00,  2.8426e-01,  8.5132e-02, -1.1955e+00,\n",
      "        -1.7678e+00,  6.2352e-01,  3.0078e-01, -1.1160e+00,  7.5381e-01,\n",
      "         4.4053e-01, -1.2386e+00, -7.8036e-01, -1.0747e+00, -7.7349e-01,\n",
      "         4.1574e-01, -1.3152e+00,  4.4885e-01, -1.3814e+00])})\n"
     ]
    }
   ],
   "source": [
    "# --- извлекаем эмбеддинги и записываем обратно в G ------------------------\n",
    "z = n2v.embedding.weight.detach().cpu()\n",
    "for n, idx in id2idx.items():\n",
    "    G.nodes[n]['n2v'] = z[idx]\n",
    "\n",
    "# --- при формировании data.x ---------------------------------------------\n",
    "# Наконец, собираем x\n",
    "num_attr_keys = [\n",
    "    'in_deg','out_deg','sent_sum','recv_sum','net_sum',\n",
    "    'pagerank','clustering',\n",
    "    'btw_centr','wcc_size','send_min','recv_min'\n",
    "]\n",
    "\n",
    "for n in G.nodes():\n",
    "    # проверяем, что всё есть\n",
    "    missing = [k for k in num_attr_keys if k not in G.nodes[n]]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"У узла {n} нет фичей {missing}\")\n",
    "    base = [float(G.nodes[n][k]) for k in num_attr_keys]\n",
    "    emb  = G.nodes[n]['n2v'].tolist()           # 128-мерный эмбеддинг\n",
    "    G.nodes[n]['x'] = torch.tensor(base + emb, dtype=torch.float)\n",
    "\n",
    "print('Пример фич узла:', list(G.nodes(data=True))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e646328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Делаем так, чтобы у всех узлов была метка\n",
    "nx.set_node_attributes(G, -1, \"label\")        # сначала всем ставим -1\n",
    "for _, row in acc_df.iterrows():              # затем переопределяем тем, что есть в accounts.csv\n",
    "    G.nodes[row.id][\"label\"] = int(bool(row.label))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9751011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# после формирования всех численных признаков, до отправки в PyG\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.stack([G.nodes[n]['x'].numpy() for n in G.nodes()])\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "for n, vec in zip(G.nodes(), X):\n",
    "    G.nodes[n]['x'] = torch.tensor(vec, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4c1f2",
   "metadata": {},
   "source": [
    "## 🔄 Конвертация в `torch_geometric.data.Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2a06745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 7\n",
      "Data(edge_index=[2, 42044], label=[32168], in_deg=[32168], out_deg=[32168], sent_sum=[32168], recv_sum=[32168], net_sum=[32168], pagerank=[32168], clustering=[32168], btw_centr=[32168], wcc_size=[32168], send_min=[32168], recv_min=[32168], n2v=[32168, 128], amount=[42044], ts=[42044], x=[32168, 7], y=[32168])\n"
     ]
    }
   ],
   "source": [
    "num_attr_keys = ['in_deg','out_deg','sent_sum','recv_sum','net_sum','pagerank','clustering']\n",
    "\n",
    "for n in G.nodes():\n",
    "    G.nodes[n]['x'] = torch.tensor([float(G.nodes[n][k]) for k in num_attr_keys], dtype=torch.float)\n",
    "\n",
    "data = from_networkx(G, group_node_attrs=['x'])\n",
    "data.y = torch.tensor([G.nodes[n].get('label', -1) for n in G.nodes()], dtype=torch.long)\n",
    "\n",
    "print(\"Num features:\", data.num_node_features)  \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9aa85510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now num features: 139\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1) Список «старых» фичей уже в data.x: shape [N,7]\n",
    "X_base = data.x                # float32, device может быть CPU или CUDA\n",
    "\n",
    "# 2) Достаём остальные скалярные фичи и приводим к форме [N,1]\n",
    "btw      = data.btw_centr.view(-1,1)   # [N] → [N,1]\n",
    "wcc      = data.wcc_size.view(-1,1)\n",
    "send_min = data.send_min.view(-1,1)\n",
    "recv_min = data.recv_min.view(-1,1)\n",
    "\n",
    "# 3) Node2Vec: shape [N,128]\n",
    "X_n2v    = data.n2v               # уже [N,128]\n",
    "\n",
    "# 4) Конкатенируем всё в один [N, 7+4+128 = 139]\n",
    "data.x = torch.cat([X_base, btw, wcc, send_min, recv_min, X_n2v], dim=1)\n",
    "\n",
    "print(\"Now num features:\", data.x.size(1))  # должно быть 139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc25dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) выгружаем data.x в NumPy\n",
    "X = data.x.cpu().numpy()   # shape [N,139]\n",
    "\n",
    "# 2) лог-трансформации неотрицательных признаков\n",
    "log_idxs = [0,1,2,3,7,8,9,10]\n",
    "X[:, log_idxs] = np.log1p(X[:, log_idxs])\n",
    "\n",
    "# 3) чистим NaN/Inf → конечные числа\n",
    "#    nan → 0.0, +inf → max_float32, -inf → min_float32\n",
    "X = np.nan_to_num(\n",
    "    X,\n",
    "    nan=0.0,\n",
    "    posinf=np.finfo(np.float32).max,\n",
    "    neginf=np.finfo(np.float32).min\n",
    ")\n",
    "\n",
    "# (можно проверить, что теперь все конечные)\n",
    "assert np.isfinite(X).all(), \"Есть ещё не-конечные элементы!\"\n",
    "\n",
    "# 4) стандартизация\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 5) обратно в TorchTensor\n",
    "import torch\n",
    "data.x = torch.tensor(X, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cd688",
   "metadata": {},
   "source": [
    "## ✂️ Train / Val / Test сплит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f9609b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 60.10%, Val: 20.03%, Test: 19.87%\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1) Собираем список узлов в порядке G.nodes()\n",
    "nodes = list(G.nodes())\n",
    "\n",
    "# 2) Хешируем каждый ID (md5 → целое), берём mod 100 → [0..99]\n",
    "hash_vals = np.array([\n",
    "    int(hashlib.md5(str(n).encode()).hexdigest(), 16) % 100\n",
    "    for n in nodes\n",
    "])\n",
    "\n",
    "# 3) Порог: [0,59] → train, [60,79] → val, [80,99] → test\n",
    "train_mask = torch.tensor(hash_vals < 60, dtype=torch.bool)\n",
    "val_mask   = torch.tensor((hash_vals >= 60) & (hash_vals < 80), dtype=torch.bool)\n",
    "test_mask  = torch.tensor(hash_vals >= 80, dtype=torch.bool)\n",
    "\n",
    "# 4) Привязываем к data\n",
    "data.train_mask = train_mask\n",
    "data.val_mask   = val_mask\n",
    "data.test_mask  = test_mask\n",
    "\n",
    "# Проверим доли\n",
    "print(f\"Train: {train_mask.sum().item()/len(nodes):.2%}, \"\n",
    "      f\"Val: {val_mask.sum().item()/len(nodes):.2%}, \"\n",
    "      f\"Test: {test_mask.sum().item()/len(nodes):.2%}\")\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.train_mask,        # корневые узлы для train\n",
    "    num_neighbors=[25, 15],             # сколько соседей на каждом слое\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.val_mask,\n",
    "    num_neighbors=[25, 15],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=data.test_mask,\n",
    "    num_neighbors=[25, 15],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1143320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сериализовано в /Users/a1234/Fraud/gnn/artifacts/eth_graph.pt\n"
     ]
    }
   ],
   "source": [
    "OUT_PATH = Path('./artifacts/eth_graph.pt')\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(data, OUT_PATH)\n",
    "print(f'Сериализовано в {OUT_PATH.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e9339",
   "metadata": {},
   "source": [
    "## 🧠 Определение GNN‑модели (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7823c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "\n",
    "# 1) Определяем GraphSAGE\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee4b5e",
   "metadata": {},
   "source": [
    "## 🏃‍♂️ Обучение и валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bc6b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: normal=1.00, fraud=1.72\n",
      "Epoch 01 | Loss 0.3746 | Train Acc 0.959 | Val Acc 0.917\n",
      "Epoch 02 | Loss 0.1162 | Train Acc 0.988 | Val Acc 0.924\n",
      "Epoch 03 | Loss 0.0525 | Train Acc 0.993 | Val Acc 0.927\n",
      "Epoch 04 | Loss 0.0246 | Train Acc 0.997 | Val Acc 0.929\n",
      "Epoch 05 | Loss 0.0181 | Train Acc 0.999 | Val Acc 0.929\n",
      "Epoch 06 | Loss 0.0091 | Train Acc 1.000 | Val Acc 0.922\n",
      "Epoch 07 | Loss 0.0048 | Train Acc 1.000 | Val Acc 0.927\n",
      "Epoch 08 | Loss 0.0060 | Train Acc 1.000 | Val Acc 0.917\n",
      "Epoch 09 | Loss 0.0091 | Train Acc 0.998 | Val Acc 0.910\n",
      "Epoch 10 | Loss 0.0337 | Train Acc 0.999 | Val Acc 0.916\n",
      "Epoch 11 | Loss 0.0150 | Train Acc 0.998 | Val Acc 0.910\n",
      "Epoch 12 | Loss 0.0251 | Train Acc 0.998 | Val Acc 0.917\n",
      "Epoch 13 | Loss 0.0651 | Train Acc 0.982 | Val Acc 0.917\n",
      "Epoch 14 | Loss 0.0734 | Train Acc 0.990 | Val Acc 0.913\n",
      "Epoch 15 | Loss 0.0455 | Train Acc 0.997 | Val Acc 0.923\n",
      "Epoch 16 | Loss 0.0201 | Train Acc 1.000 | Val Acc 0.924\n",
      "Epoch 17 | Loss 0.0052 | Train Acc 0.996 | Val Acc 0.922\n",
      "Epoch 18 | Loss 0.0049 | Train Acc 1.000 | Val Acc 0.926\n",
      "Epoch 19 | Loss 0.0018 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 20 | Loss 0.0014 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 21 | Loss 0.0012 | Train Acc 1.000 | Val Acc 0.932\n",
      "Epoch 22 | Loss 0.0012 | Train Acc 1.000 | Val Acc 0.935\n",
      "Epoch 23 | Loss 0.0012 | Train Acc 1.000 | Val Acc 0.936\n",
      "Epoch 24 | Loss 0.0012 | Train Acc 1.000 | Val Acc 0.938\n",
      "Epoch 25 | Loss 0.0013 | Train Acc 1.000 | Val Acc 0.939\n",
      "Epoch 26 | Loss 0.0013 | Train Acc 1.000 | Val Acc 0.936\n",
      "Epoch 27 | Loss 0.0013 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 28 | Loss 0.0014 | Train Acc 1.000 | Val Acc 0.929\n",
      "Epoch 29 | Loss 0.0015 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 30 | Loss 0.0015 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 31 | Loss 0.0014 | Train Acc 1.000 | Val Acc 0.932\n",
      "Epoch 32 | Loss 0.0015 | Train Acc 1.000 | Val Acc 0.932\n",
      "Epoch 33 | Loss 0.0015 | Train Acc 1.000 | Val Acc 0.932\n",
      "Epoch 34 | Loss 0.0015 | Train Acc 1.000 | Val Acc 0.932\n",
      "Epoch 35 | Loss 0.0015 | Train Acc 1.000 | Val Acc 0.933\n",
      "Epoch 36 | Loss 0.0015 | Train Acc 1.000 | Val Acc 0.929\n",
      "Epoch 37 | Loss 0.0016 | Train Acc 1.000 | Val Acc 0.932\n",
      "Epoch 38 | Loss 0.0016 | Train Acc 1.000 | Val Acc 0.924\n",
      "Epoch 39 | Loss 0.0016 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 40 | Loss 0.0016 | Train Acc 1.000 | Val Acc 0.929\n",
      "Epoch 41 | Loss 0.0016 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 42 | Loss 0.0016 | Train Acc 1.000 | Val Acc 0.929\n",
      "Epoch 43 | Loss 0.0016 | Train Acc 1.000 | Val Acc 0.930\n",
      "Epoch 44 | Loss 0.0020 | Train Acc 0.997 | Val Acc 0.923\n",
      "Epoch 45 | Loss 0.1099 | Train Acc 0.970 | Val Acc 0.922\n",
      "Epoch 46 | Loss 0.2335 | Train Acc 0.967 | Val Acc 0.910\n",
      "Epoch 47 | Loss 0.1130 | Train Acc 0.987 | Val Acc 0.926\n",
      "Epoch 48 | Loss 0.0478 | Train Acc 0.995 | Val Acc 0.936\n",
      "Epoch 49 | Loss 0.0122 | Train Acc 0.999 | Val Acc 0.935\n",
      "Epoch 50 | Loss 0.0057 | Train Acc 1.000 | Val Acc 0.938\n",
      "✅ Test Accuracy: 0.911\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "labels = data.y[data.y != -1]\n",
    "counts = torch.bincount(labels)\n",
    "weight = torch.tensor([1.0, counts[0].float() / counts[1].float()], device=device)\n",
    "print(f\"Class weights: normal={weight[0]:.2f}, fraud={weight[1]:.2f}\")\n",
    "\n",
    "# 3) Инициализируем модель, optimizer, criterion (с весами из шага 2)\n",
    "model = GraphSAGE(data.num_node_features, 64, int(data.y.max().item())+1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weight, ignore_index=-1)\n",
    "\n",
    "# 4) Цикл обучения\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        # только первые batch.batch_size предсказаний — для корневых узлов\n",
    "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.batch_size\n",
    "    return total_loss / int(data.train_mask.sum())\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        logits = out[:batch.batch_size]\n",
    "        y = batch.y[:batch.batch_size]\n",
    "\n",
    "        # Только размеченные\n",
    "        mask = (y != -1)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += int((preds[mask] == y[mask]).sum())\n",
    "        total   += int(mask.sum())\n",
    "\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train_epoch()\n",
    "    train_acc = eval_loader(train_loader)\n",
    "    val_acc   = eval_loader(val_loader)\n",
    "    print(f'Epoch {epoch:02d} | Loss {loss:.4f} | Train Acc {train_acc:.3f} | Val Acc {val_acc:.3f}')\n",
    "\n",
    "test_acc = eval_loader(test_loader)\n",
    "print(f'✅ Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115f6d0",
   "metadata": {},
   "source": [
    "## 📊 Визуализация результатов\n",
    "Вычислим метрики на тестовой выборке и отобразим матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1091d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.952     0.905     0.928       369\n",
      "           1      0.852     0.922     0.885       218\n",
      "\n",
      "    accuracy                          0.911       587\n",
      "   macro avg      0.902     0.914     0.907       587\n",
      "weighted avg      0.914     0.911     0.912       587\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "for batch in test_loader:\n",
    "    batch = batch.to(device)\n",
    "    out = model(batch.x, batch.edge_index)\n",
    "    logits = out[:batch.batch_size]\n",
    "    y = batch.y[:batch.batch_size]\n",
    "    mask = (y != -1)\n",
    "\n",
    "    all_preds.append(logits.argmax(dim=1)[mask].cpu())\n",
    "    all_labels.append(y[mask].cpu())\n",
    "\n",
    "y_true = torch.cat(all_labels).numpy()\n",
    "y_pred = torch.cat(all_preds).numpy()\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix (Test)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f0a29",
   "metadata": {},
   "source": [
    "## 🕵️‍♂️ Интерпретация предсказаний с **GNNExplainer**\n",
    "Выберем произвольный корректно классифицированный узел из тестовой выборки и посмотрим, какие рёбра и признаки были наиболее важны для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e96cf",
   "metadata": {},
   "source": [
    "## 💾 Сохранение обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b195ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в /Users/a1234/Fraud/gnn/checkpoints/gcn_model.pt\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = Path('./checkpoints/gcn_model.pt')\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f'Модель сохранена в {MODEL_PATH.resolve()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
