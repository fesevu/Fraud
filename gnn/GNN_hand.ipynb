{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4bb02a",
   "metadata": {},
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbb52b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3302.78s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (25.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (75.3.2)\n",
      "Requirement already satisfied: wheel in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3309.38s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.4.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.1) (4.13.2)\n",
      "Requirement already satisfied: sympy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch==2.4.1) (2025.3.0)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from jinja2->torch==2.4.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from sympy->torch==2.4.1) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3315.18s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3322.88s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-scatter in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.1.2)\n",
      "Requirement already satisfied: torch-sparse in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (0.6.18)\n",
      "Requirement already satisfied: torch-cluster in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.6.3)\n",
      "Requirement already satisfied: torch-spline-conv in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scipy->torch-sparse) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3328.66s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric==2.2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (3.1.6)\n",
      "Requirement already satisfied: requests in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (3.1.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from torch-geometric==2.2.0) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from jinja2->torch-geometric==2.2.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch-geometric==2.2.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch-geometric==2.2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch-geometric==2.2.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from requests->torch-geometric==2.2.0) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn->torch-geometric==2.2.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn->torch-geometric==2.2.0) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3334.44s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: networkx in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (3.1)\n",
      "Requirement already satisfied: matplotlib in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: rich in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (14.0.0)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from rich) (2.19.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from rich) (4.13.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3341.40s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphlime in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: focal-loss-torch in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (0.1.2)\n",
      "Collecting stella\n",
      "  Using cached stella-0.1.0.tar.gz (13.0 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: torch in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from focal-loss-torch) (2.4.1)\n",
      "Requirement already satisfied: numpy in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from focal-loss-torch) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /Users/a1234/Fraud/.venv/lib/python3.8/site-packages (from stella) (4.67.1)\n",
      "Collecting astropy (from stella)\n",
      "  Using cached astropy-5.2.2-cp38-cp38-macosx_11_0_arm64.whl.metadata (8.2 kB)\n",
      "Collecting astroquery (from stella)\n",
      "  Using cached astroquery-0.4.7-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting sklearn (from stella)\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 0. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ pip –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å–±–æ—Ä–∫–∏\n",
    "%pip install -U pip setuptools wheel\n",
    "\n",
    "# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch (CPU-–≤–µ—Ä—Å–∏—è)\n",
    "%pip install torch==2.4.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "# 2. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ typing-extensions\n",
    "%pip install -U typing-extensions\n",
    "\n",
    "# 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π PyTorch Geometric\n",
    "%pip install torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
    "%pip install torch-geometric==2.2.0\n",
    "\n",
    "# 4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Ç–∏–ª–∏—Ç\n",
    "%pip install -U scikit-learn pandas networkx matplotlib rich tqdm\n",
    "%pip install graphlime focal-loss-torch stella tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b59b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, recall_score, confusion_matrix\n",
    "import torch.optim as optim\n",
    "from torch_geometric.utils import add_self_loops\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "import networkx as nx\n",
    "from torch_geometric.explain.algorithm.gnn_explainer import GNNExplainer_\n",
    "import joblib\n",
    "from collections import OrderedDict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import FullBatchNodeGenerator\n",
    "from stellargraph.layer import DirectedGraphSAGE\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from stellargraph.mapper import DirectedGraphSAGENodeGenerator\n",
    "from stellargraph.layer import DirectedGraphSAGE\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from stellargraph.layer.gcn import GCN\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489d9be",
   "metadata": {},
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4daa09ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'data'...\n",
      "remote: Enumerating objects: 75, done.\u001b[K\n",
      "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 75 (delta 35), reused 4 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (75/75), 31.54 MiB | 651.00 KiB/s, done.\n",
      "Resolving deltas: 100% (35/35), done.\n",
      "‚úÖ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "#@title üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ)\n",
    "import os\n",
    "\n",
    "# –ü–∞–ø–∫–∞, –∫—É–¥–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π\n",
    "data_dir = 'data/'\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–∞–ø–∫–∞\n",
    "if os.path.exists(data_dir):\n",
    "    # –ï—Å–ª–∏ –ø–∞–ø–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —É–¥–∞–ª—è–µ–º –≤—Å–µ –µ—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ\n",
    "    for root, dirs, files in os.walk(data_dir, topdown=False):\n",
    "        for name in files:\n",
    "            os.remove(os.path.join(root, name))\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))\n",
    "else:\n",
    "    # –ï—Å–ª–∏ –ø–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ—ë\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "\n",
    "# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –≤ –ø–∞–ø–∫—É data\n",
    "!git clone https://github.com/salam-ammari/Labeled-Transactions-based-Dataset-of-Ethereum-Network.git {data_dir}\n",
    "\n",
    "\n",
    "import zipfile, pathlib\n",
    "zip_path = \"data/Dataset.zip\"\n",
    "extract_path = pathlib.Path(\"data/unpacked\")\n",
    "with zipfile.ZipFile(zip_path) as zf: zf.extractall(extract_path)\n",
    "print(\"‚úÖ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97efc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71250, 18) —Å—Ç—Ä–æ–∫\n",
      "['hash', 'nonce', 'transaction_index', 'from_address', 'to_address', 'value', 'gas', 'gas_price', 'input', 'receipt_cumulative_gas_used', 'receipt_gas_used', 'block_timestamp', 'block_number', 'block_hash', 'from_scam', 'to_scam', 'from_category', 'to_category']\n"
     ]
    }
   ],
   "source": [
    "#@title üßπ –ß—Ç–µ–Ω–∏–µ CSV\n",
    "import pandas as pd\n",
    "dataset_csv_path = extract_path / \"Dataset\" / \"Dataset.csv\"\n",
    "df = pd.read_csv(dataset_csv_path)\n",
    "print(df.shape, \"—Å—Ç—Ä–æ–∫\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6288dc0",
   "metadata": {},
   "source": [
    "# –ò–Ω–∂–µ–Ω–µ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185a22b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " hash                               0\n",
      "nonce                              0\n",
      "transaction_index                  0\n",
      "from_address                       0\n",
      "to_address                         0\n",
      "value                              0\n",
      "gas                                0\n",
      "gas_price                          0\n",
      "input                              0\n",
      "receipt_cumulative_gas_used        0\n",
      "receipt_gas_used                   0\n",
      "block_timestamp                    0\n",
      "block_number                       0\n",
      "block_hash                         0\n",
      "from_scam                          0\n",
      "to_scam                            0\n",
      "from_category                  68622\n",
      "to_category                    59601\n",
      "dtype: int64\n",
      "Dropped rows with missing values. New shape: (27, 18)\n",
      "Duplicate rows count: 11\n",
      "Dropped duplicate rows. New shape: (16, 18)\n",
      "Dataframe after feature engineering: (16, 17)\n",
      "Edge features: ['gas', 'gas_price', 'receipt_cumulative_gas_used', 'receipt_gas_used', 'block_number', 'value_cat', 'from_years_in_operation', 'to_years_in_operation']\n",
      "Node features: ['from_reg_year', 'to_reg_year', 'from_max_value', 'to_max_value']\n",
      "Response columns: ['from_scam', 'to_scam']\n",
      "\n",
      "Preview of selected features at various positions:\n",
      "\n",
      "      gas     gas_price  receipt_cumulative_gas_used  receipt_gas_used  block_number  value_cat  from_years_in_operation  to_years_in_operation  from_reg_year  to_reg_year  from_max_value  to_max_value  from_scam  to_scam\n",
      "0   21000  6.100000e+10                       330593             21000       4767697          1                        2                      2           2017         2017    1.020000e+20  1.020000e+20          1        1\n",
      "8   21000  2.000000e+10                      2777100             21000       5511845          2                        1                      1           2018         2018    1.890000e+19  1.890000e+19          1        1\n",
      "15  21000  5.000000e+10                       220968             21000       7682123          0                        0                      0           2019         2019    1.000000e+14  1.000000e+14          1        1\n"
     ]
    }
   ],
   "source": [
    "# %% [data scrubbing]\n",
    "# Check for missing values and drop if any\n",
    "missing_counts = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_counts)\n",
    "if missing_counts.any():\n",
    "    df = df.dropna()\n",
    "    print(\"Dropped rows with missing values. New shape:\", df.shape)\n",
    "else:\n",
    "    print(\"No missing values found.\")\n",
    "\n",
    "# Check for duplicate rows and drop if any\n",
    "dup_count = df.duplicated().sum()\n",
    "print(\"Duplicate rows count:\", dup_count)\n",
    "if dup_count > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Dropped duplicate rows. New shape:\", df.shape)\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")\n",
    "# %% [feature engineering]\n",
    "# Reload dataframe if block_timestamp column was dropped in a previous run\n",
    "if 'block_timestamp' not in df.columns:\n",
    "    df = pd.read_csv(dataset_csv_path)\n",
    "# Extract year directly from block_timestamp string\n",
    "df['block_year'] = df['block_timestamp'].str[:4].astype(int)\n",
    "\n",
    "# Categorize transaction values into 3 quantile-based categories\n",
    "df['value_cat'] = pd.qcut(df['value'], q=3, labels=False)\n",
    "\n",
    "# Compute registration year (first seen block year) per node address\n",
    "from_reg = df.groupby('from_address')['block_year'].min().rename('from_reg_year')\n",
    "to_reg   = df.groupby('to_address')['block_year'].min().rename('to_reg_year')\n",
    "df = df.merge(from_reg, on='from_address', how='left').merge(to_reg, on='to_address', how='left')\n",
    "\n",
    "# Compute years in operation based on the latest block year in the dataset\n",
    "current_year = df['block_year'].max()\n",
    "df['from_years_in_operation'] = current_year - df['from_reg_year']\n",
    "df['to_years_in_operation']   = current_year - df['to_reg_year']\n",
    "\n",
    "# Compute max transaction value per node address\n",
    "from_max = df.groupby('from_address')['value'].max().rename('from_max_value')\n",
    "to_max   = df.groupby('to_address')['value'].max().rename('to_max_value')\n",
    "df = df.merge(from_max, on='from_address', how='left').merge(to_max, on='to_address', how='left')\n",
    "\n",
    "# Drop unneeded columns\n",
    "cols_to_drop = [\n",
    "    'hash', 'nonce', 'transaction_index', 'input',\n",
    "    'block_timestamp', 'block_hash',\n",
    "    'from_category', 'to_category', 'value'\n",
    "]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Define feature sets\n",
    "edge_features   = [\n",
    "    'gas', 'gas_price', 'receipt_cumulative_gas_used', 'receipt_gas_used',\n",
    "    'block_number', 'value_cat', 'from_years_in_operation', 'to_years_in_operation'\n",
    "]\n",
    "node_features   = ['from_reg_year', 'to_reg_year', 'from_max_value', 'to_max_value']\n",
    "response_cols   = ['from_scam', 'to_scam']\n",
    "\n",
    "print(\"Dataframe after feature engineering:\", df.shape)\n",
    "print(\"Edge features:\", edge_features)\n",
    "print(\"Node features:\", node_features)\n",
    "print(\"Response columns:\", response_cols)\n",
    "\n",
    "# %% [data preview]\n",
    "# Show sample records from beginning, middle, and end for clarity\n",
    "sample_idxs = [0, df.shape[0] // 2, df.shape[0] - 1]\n",
    "preview_df = df.loc[sample_idxs, edge_features + node_features + response_cols]\n",
    "print(\"\\nPreview of selected features at various positions:\\n\")\n",
    "print(preview_df.to_string(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f224b60",
   "metadata": {},
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087ed21e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be a SparseTensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m\n\u001b[1;32m     21\u001b[0m G \u001b[38;5;241m=\u001b[39m sg\u001b[38;5;241m.\u001b[39mStellarGraph(\n\u001b[1;32m     22\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnode_features_df,\n\u001b[1;32m     23\u001b[0m     edges\u001b[38;5;241m=\u001b[39medges_sg,\n\u001b[1;32m     24\u001b[0m     node_type_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     edge_type_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransaction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Full-batch generator with self-loops and dense adjacency via transform\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mFullBatchNodeGenerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mself_loops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Define GCN model with specified layer sizes\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Define GCN model with specified layer sizes\u001b[39;00m\n\u001b[1;32m     38\u001b[0m layer_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/stellargraph/mapper/full_batch_generators.py:113\u001b[0m, in \u001b[0;36mFullBatchGenerator.__init__\u001b[0;34m(self, G, name, method, k, sparse, transform, teleport_probability, weighted)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(transform):\n\u001b[0;32m--> 113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAadj \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAadj\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(features, A)\u001b[0m\n\u001b[1;32m     21\u001b[0m G \u001b[38;5;241m=\u001b[39m sg\u001b[38;5;241m.\u001b[39mStellarGraph(\n\u001b[1;32m     22\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnode_features_df,\n\u001b[1;32m     23\u001b[0m     edges\u001b[38;5;241m=\u001b[39medges_sg,\n\u001b[1;32m     24\u001b[0m     node_type_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     edge_type_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransaction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Full-batch generator with self-loops and dense adjacency via transform\u001b[39;00m\n\u001b[1;32m     29\u001b[0m generator \u001b[38;5;241m=\u001b[39m FullBatchNodeGenerator(\n\u001b[1;32m     30\u001b[0m     G,\n\u001b[1;32m     31\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself_loops\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m---> 33\u001b[0m     transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m features, A: (features, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Define GCN model with specified layer sizes\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Define GCN model with specified layer sizes\u001b[39;00m\n\u001b[1;32m     38\u001b[0m layer_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/tensorflow/python/ops/sparse_ops.py:1714\u001b[0m, in \u001b[0;36msparse_tensor_to_dense\u001b[0;34m(sp_input, default_value, validate_indices, name)\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse.to_dense\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse.to_dense\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_tensor_to_dense\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_endpoints(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_tensor_to_dense\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msparse_tensor_to_dense\u001b[39m(sp_input,\n\u001b[1;32m   1674\u001b[0m                            default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1675\u001b[0m                            validate_indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1676\u001b[0m                            name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a `SparseTensor` into a dense tensor.\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03m  For this sparse tensor with three non-empty values:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;124;03m    TypeError: If `sp_input` is not a `SparseTensor`.\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1714\u001b[0m   sp_input \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_to_sparse_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msp_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m default_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1716\u001b[0m     default_value \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mzeros([], dtype\u001b[38;5;241m=\u001b[39msp_input\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Fraud/.venv/lib/python3.8/site-packages/tensorflow/python/ops/sparse_ops.py:68\u001b[0m, in \u001b[0;36m_convert_to_sparse_tensor\u001b[0;34m(sp_input)\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensor\u001b[38;5;241m.\u001b[39mfrom_value(sp_input)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sp_input, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensor):\n\u001b[0;32m---> 68\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a SparseTensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sp_input\n",
      "\u001b[0;31mTypeError\u001b[0m: Input must be a SparseTensor."
     ]
    }
   ],
   "source": [
    "# %% [model definition]\n",
    "# Build StellarGraph for directed transactions\n",
    "# Prepare edge DataFrame\n",
    "edges_sg = pd.DataFrame({\n",
    "    \"source\": df[\"from_address\"],\n",
    "    \"target\": df[\"to_address\"],\n",
    "    **{feat: df[feat] for feat in edge_features}\n",
    "})\n",
    "\n",
    "# Prepare node features by averaging duplicates\n",
    "node_feat_from = df[[\"from_address\"] + node_features].rename(columns={\"from_address\": \"id\"}).set_index(\"id\")\n",
    "node_feat_to   = df[[\"to_address\"]   + node_features].rename(columns={\"to_address\":   \"id\"}).set_index(\"id\")\n",
    "node_features_df = pd.concat([node_feat_from, node_feat_to]).groupby(level=0).mean()\n",
    "\n",
    "# Scale node features to zero mean and unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "node_features_df[:] = scaler.fit_transform(node_features_df)\n",
    "\n",
    "# Create StellarGraph object\n",
    "G = sg.StellarGraph(\n",
    "    nodes=node_features_df,\n",
    "    edges=edges_sg,\n",
    "    node_type_default=\"address\",\n",
    "    edge_type_default=\"transaction\"\n",
    ")\n",
    "\n",
    "# Full-batch generator with self-loops and dense adjacency via transform\n",
    "generator = FullBatchNodeGenerator(\n",
    "    G,\n",
    "    method=\"self_loops\",\n",
    "    sparse=True,\n",
    "    transform=lambda features, A: (features, tf.sparse.to_dense(A))\n",
    ")\n",
    "\n",
    "# Define GCN model with specified layer sizes\n",
    "# Define GCN model with specified layer sizes\n",
    "layer_sizes = [4, 32, 16, 16, 16, 4]\n",
    "gcn = GCN(\n",
    "    layer_sizes=layer_sizes,\n",
    "    activations=[\"relu\"] * len(layer_sizes),\n",
    "    generator=generator,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "# Build input/output tensors and add output layer\n",
    "x_inp, x_out = gcn.in_out_tensors()\n",
    "prediction = Dense(units=2, activation=\"softmax\")(x_out)\n",
    "\n",
    "# Assemble and compile model\n",
    "model = Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss=categorical_crossentropy,\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f7cc9",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54ef2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# %% [model training]\n",
    "# Prepare node labels for classification: aggregate scam flag per node\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Aggregate scam labels by node (1 if any transaction flagged)\n",
    "from_labels = df.groupby(\"from_address\")[\"from_scam\"].max().rename(\"scam\")\n",
    "to_labels   = df.groupby(\"to_address\")[\"to_scam\"].max().rename(\"scam\")\n",
    "node_labels = pd.concat([from_labels, to_labels]).groupby(level=0).max()\n",
    "\n",
    "# One-hot encode labels\n",
    "node_targets = pd.get_dummies(node_labels).sort_index()\n",
    "\n",
    "# Split nodes into train (50%), validation (25%), test (25%)\n",
    "nodes = node_targets.index\n",
    "train_nodes, temp_nodes = train_test_split(\n",
    "    nodes,\n",
    "    train_size=0.5,\n",
    "    stratify=node_targets,\n",
    "    random_state=42\n",
    ")\n",
    "val_nodes, test_nodes = train_test_split(\n",
    "    temp_nodes,\n",
    "    train_size=0.5,\n",
    "    stratify=node_targets.loc[temp_nodes],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_targets = node_targets.loc[train_nodes]\n",
    "val_targets   = node_targets.loc[val_nodes]\n",
    "test_targets  = node_targets.loc[test_nodes]\n",
    "\n",
    "# Create generators for training, validation, and testing\n",
    "train_gen = generator.flow(train_nodes, train_targets.values)\n",
    "val_gen   = generator.flow(val_nodes,   val_targets.values)\n",
    "test_gen  = generator.flow(test_nodes,  test_targets.values)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model for 20 epochs with validation\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    validation_data=val_gen,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, accuracy = model.evaluate(test_gen, verbose=0)\n",
    "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
