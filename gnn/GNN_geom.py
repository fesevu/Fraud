# %%
%pip uninstall pyg-lib torch-sparse -y
# 2.1 PyTorch (CPU) ‚Äì –ø–æ–¥–º–µ–Ω–∏—Ç–µ –∏–Ω–¥–µ–∫—Å, –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ CUDA
%pip install torch==2.6.0 torchvision torchaudio

# 2.2 PyG: —Å 2.3+ –≤–Ω–µ—à–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –ø–æ—á—Ç–∏ –Ω–µ—Ç, —Å—Ç–∞–≤–∏–º –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
%pip install torch_geometric 
%pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cpu.html


# 2.4 –æ—Å—Ç–∞–ª—å–Ω–æ–µ
%pip install xgboost pandas matplotlib graphviz scikit-learn tqdm numpy networkx seaborn

# 2.5 –µ—Å–ª–∏ drawSchema –≤—ã–¥–∞—ë—Ç –æ—à–∏–±–∫—É ‚ÄúGraphviz executable not found‚Äù:
#   Ubuntu: sudo apt-get install graphviz
#   macOS:  brew install graphviz

# %%
from pathlib import Path
import networkx as nx
import pandas as pd
import numpy as np
import torch
from torch_geometric.data import Data
from torch_geometric.utils import from_networkx

print(torch.__version__)

# %% [markdown]
# # –ß—Ç–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞

# %%
from pathlib import Path
ACCOUNTS_CSV = Path('./tmp/Ethereum/account.csv')      # –æ–±–Ω–æ–≤–∏—Ç–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
TXS_CSV      = Path('./tmp/Ethereum/transaction.csv')   # –æ–±–Ω–æ–≤–∏—Ç–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

assert ACCOUNTS_CSV.exists(), f'{ACCOUNTS_CSV} not found'
assert TXS_CSV.exists(), f'{TXS_CSV} not found'

# %%
acc_df = pd.read_csv(ACCOUNTS_CSV, header=None, names=['id', 'label'])
tx_df  = pd.read_csv(TXS_CSV, header=None, names=['src', 'dst', 'amount', 'timestamp'])

display(acc_df.head())
display(tx_df.head())

# %% [markdown]
# ## üèóÔ∏è –°–±–æ—Ä–∫–∞ –≥—Ä–∞—Ñ–∞

# %%
G = nx.DiGraph()

# add nodes
for _, row in acc_df.iterrows():
    G.add_node(row.id, label=int(bool(row.label)))

# add edges
for _, row in tx_df.iterrows():
    G.add_edge(row.src, row.dst, amount=float(row.amount), ts=float(row.timestamp))

print(f'–ì—Ä–∞—Ñ —Å–æ–¥–µ—Ä–∂–∏—Ç {G.number_of_nodes():,} —É–∑–ª–æ–≤ –∏ {G.number_of_edges():,} —Ä—ë–±–µ—Ä')

# %%
# –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
in_deg  = dict(G.in_degree())
out_deg = dict(G.out_degree())

# –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å—É–º–º—ã
sent_sum = {n: 0.0 for n in G.nodes()}
recv_sum = {n: 0.0 for n in G.nodes()}
for u, v, d in G.edges(data=True):
    amt = d['amount']
    sent_sum[u] += amt
    recv_sum[v] += amt

# PageRank –∏ –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
pr = nx.pagerank(G, alpha=0.85)
clust = nx.clustering(G.to_undirected())

# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∏—á–∏ –≤ –≥—Ä–∞—Ñ
for n in G.nodes():
    G.nodes[n].update({
        'in_deg':      in_deg.get(n, 0),
        'out_deg':     out_deg.get(n, 0),
        'sent_sum':    sent_sum[n],
        'recv_sum':    recv_sum[n],
        'net_sum':     sent_sum[n] - recv_sum[n],
        'pagerank':    pr[n],
        'clustering':  clust[n],
    })

print('–ü—Ä–∏–º–µ—Ä —Ñ–∏—á —É–∑–ª–∞:', list(G.nodes(data=True))[0])

# %%
# üîß –î–µ–ª–∞–µ–º —Ç–∞–∫, —á—Ç–æ–±—ã —É –≤—Å–µ—Ö —É–∑–ª–æ–≤ –±—ã–ª–∞ –º–µ—Ç–∫–∞
nx.set_node_attributes(G, -1, "label")        # —Å–Ω–∞—á–∞–ª–∞ –≤—Å–µ–º —Å—Ç–∞–≤–∏–º -1
for _, row in acc_df.iterrows():              # –∑–∞—Ç–µ–º –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤ accounts.csv
    G.nodes[row.id]["label"] = int(bool(row.label))   

# %% [markdown]
# ## üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ `torch_geometric.data.Data`

# %%
num_attr_keys = ['in_deg','out_deg','sent_sum','recv_sum','net_sum','pagerank','clustering']

for n in G.nodes():
    G.nodes[n]['x'] = torch.tensor([float(G.nodes[n][k]) for k in num_attr_keys], dtype=torch.float)

data = from_networkx(G, group_node_attrs=['x'])
data.y = torch.tensor([G.nodes[n].get('label', -1) for n in G.nodes()], dtype=torch.long)

print(data)

# %% [markdown]
# ## ‚úÇÔ∏è Train / Val / Test —Å–ø–ª–∏—Ç

# %%
torch.manual_seed(42)
N = data.num_nodes
perm = torch.randperm(N)
n_train = int(0.6 * N)
n_val   = int(0.2 * N)

data.train_mask = torch.zeros(N, dtype=torch.bool)
data.val_mask   = torch.zeros(N, dtype=torch.bool)
data.test_mask  = torch.zeros(N, dtype=torch.bool)

data.train_mask[perm[:n_train]]           = True
data.val_mask[perm[n_train:n_train+n_val]] = True
data.test_mask[perm[n_train+n_val:]]      = True

print(f'Train: {data.train_mask.sum().item()}, Val: {data.val_mask.sum().item()}, Test: {data.test_mask.sum().item()}')

# %%
OUT_PATH = Path('./artifacts/eth_graph.pt')
OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
torch.save(data, OUT_PATH)
print(f'–°–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ {OUT_PATH.resolve()}')

# %% [markdown]
# ## üß† –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GNN‚Äë–º–æ–¥–µ–ª–∏ (GCN)

# %%
from torch_geometric.nn import GCNConv
import torch.nn.functional as F

class GCN(torch.nn.Module):
    def __init__(self, in_channels: int, hidden_channels: int, num_classes: int):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return x

print('GCN model ready')

# %% [markdown]
# ## üèÉ‚Äç‚ôÇÔ∏è –û–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è

# %%
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GCN(data.num_node_features, 64, int(data.y.max().item()) + 1).to(device)
data = data.to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

labeled = (data.y != -1)
perm = torch.randperm(int(labeled.sum()))
idx  = labeled.nonzero(as_tuple=False).view(-1)[perm]

n_train = int(0.6 * len(idx))
n_val   = int(0.2 * len(idx))

data.train_mask[:] = False
data.val_mask[:]   = False
data.test_mask[:]  = False

data.train_mask[idx[:n_train]]           = True
data.val_mask[idx[n_train:n_train+n_val]] = True
data.test_mask[idx[n_train+n_val:]]      = True

def train():
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    return loss.item()

@torch.no_grad()
def accuracy(mask):
    model.eval()
    logits = model(data.x, data.edge_index)
    preds = logits.argmax(dim=1)
    correct = (preds[mask] == data.y[mask]).sum().item()
    return correct / int(mask.sum())

for epoch in range(1, 201):
    loss = train()
    if epoch % 10 == 0:
        train_acc = accuracy(data.train_mask)
        val_acc = accuracy(data.val_mask)
        print(f'Epoch {epoch:03d} | Loss {loss:.4f} | Train Acc {train_acc:.3f} | Val Acc {val_acc:.3f}')

test_acc = accuracy(data.test_mask)
print(f'‚úÖ Test Accuracy: {test_acc:.3f}')

# %% [markdown]
# ## üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# –í—ã—á–∏—Å–ª–∏–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –∏ –æ—Ç–æ–±—Ä–∞–∑–∏–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫.

# %%
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

model.eval()
logits = model(data.x, data.edge_index)
preds  = logits.argmax(dim=1)

mask = (data.test_mask) & (data.y != -1)
y_true, y_pred = data.y[mask].cpu(), preds[mask].cpu()

print(classification_report(y_true, y_pred, digits=3))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d')
plt.title('Confusion Matrix (Test)')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# %% [markdown]
# ## üïµÔ∏è‚Äç‚ôÇÔ∏è –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å **GNNExplainer**
# –í—ã–±–µ—Ä–µ–º –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —É–∑–µ–ª –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ —Ä—ë–±—Ä–∞ –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –±—ã–ª–∏ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã –¥–ª—è –º–æ–¥–µ–ª–∏.

# %%
from torch_geometric.explain import Explainer, GNNExplainer

# --------------------- 1. –∑–∞–±–∏—Ä–∞–µ–º –ø–æ–¥–≥—Ä–∞—Ñ –≤–æ–∫—Ä—É–≥ –Ω—É–∂–Ω–æ–≥–æ –∞–¥—Ä–µ—Å–∞ ---------------------
target_addr = "0x5093c4029acab3aff80140023099f5ec6ca7d52f"
# train_loader.fetch –≤–µ—Ä–Ω—ë—Ç —Å–ø–∏—Å–æ–∫ Data-–æ–±—ä–µ–∫—Ç–æ–≤; –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π
data = train_loader.fetch([{"type": "Account", "primary_id": target_addr}])[0]

# --------------------- 2. –≤–∫–ª—é—á–∞–µ–º eval-—Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏ ---------------------------------
gs.model.eval()                       # –≤–∞–∂–Ω–æ: –Ω–∏ dropout, –Ω–∏ BN-–∞–ø–¥–µ–π—Ç–æ–≤

# --------------------- 3. –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Explainer (–Ω–æ–≤–æ–µ API) --------------------------
from torch_geometric.explain import Explainer, GNNExplainer

explainer = Explainer(
    model=gs.model,                          # –≤–∞—à–∞ –æ–±—É—á–µ–Ω–Ω–∞—è GNN
    algorithm=GNNExplainer(epochs=200),      # 200 —ç–ø–æ—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
    explanation_type="model",                # –æ–±—ä—è—Å–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    node_mask_type="attributes",             # –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —É–∑–ª–∞
    edge_mask_type="object",                 # –≤–∞–∂–Ω–æ—Å—Ç—å —Ä—ë–±–µ—Ä
    model_config=dict(
        mode="binary_classification",        # 0/1 –º–µ—Ç–∫–∏
        task_level="node",
        return_type="raw",                   # –º–æ–¥–µ–ª—å –≤—ã–¥–∞—ë—Ç logits
    ),
)

# --------------------- 4. —Å—á–∏—Ç–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ -----------------------------------------
# –ï—Å–ª–∏ –ø–æ–¥–≥—Ä–∞—Ñ —É–∂–µ –æ–±—Ä–µ–∑–∞–Ω –¥–æ –æ–¥–Ω–æ–π –≤–µ—Ä—à–∏–Ω—ã ‚Äì index=None.
# –ï—Å–ª–∏ —Ç–∞–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–µ—Ä—à–∏–Ω, —É–∫–∞–∂–∏—Ç–µ –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Ü–µ–ª–µ–≤–æ–π (–æ–±—ã—á–Ω–æ 0).
explanation = explainer(
    x=data.x.float(), 
    edge_index=data.edge_index, 
    index=None,              # –∏–ª–∏ 0 / int(<–Ω—É–∂–Ω–∞—è_–≤–µ—Ä—à–∏–Ω–∞>)
    target=data.y[0].item()  # –∫–∞–∫–æ–π –∫–ª–∞—Å—Å –æ–±—ä—è—Å–Ω—è–µ–º
)

# --------------------- 5. –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ------------------------------------------------
explanation.visualize_feature_importance(
    top_k=len(train_loader.v_in_feats),
    feat_labels=train_loader.v_in_feats,
)
explanation.visualize_graph()  # –ø–æ–∫–∞–∂–µ—Ç —Å—É–±–≥—Ä–∞—Ñ –∏ –≤–µ—Å–∞ —Ä—ë–±–µ—Ä


# %% [markdown]
# ## üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

# %%
MODEL_PATH = Path('./checkpoints/gcn_model.pt')
MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)
torch.save(model.state_dict(), MODEL_PATH)
print(f'–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH.resolve()}')


